{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AEVB Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Version Log\n",
    "\n",
    "1. 2020/04/22: first baseline version created.\n",
    "    - alpha: 0.01 does not work, can train with 0.001\n",
    "2. 2020/04/24: \n",
    "    - ADAM\n",
    "        - implemented ADAM\n",
    "        - added functionality to output file status during training\n",
    "        - added flexibility to start training based on user-specified parameters\n",
    "    - profiling\n",
    "3. 2020/04/25:\n",
    "    - speed up\n",
    "        - updated training function to take in grad as function for easier testing\n",
    "4. 2020/04/28:\n",
    "    - \"total_loss\"\n",
    "        - corrected error in \"total_loss\" function though it didn't have any effect before as L has been set to 1\n",
    "5. 2020/04/30:\n",
    "    - finalized with each version and all workings documented and tidied up\n",
    "6. 2020/05/07 (section 7.6):\n",
    "    - model correction\n",
    "        - model specification mistake where the same latent variable sample is used across all data points\n",
    "    - train function\n",
    "        - from discussion with VR, update train function so that X is expected to be M by dx, rather than M by Xdim1 by Xdim2 which is rather arbitrary for MNIST data\n",
    "7. 2020/05/08 (section 7.7):\n",
    "    - try Eigen + pybind\n",
    "    - align MDN version to model version in section 7, this is v5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_version = \"v5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Variable Dimensions\n",
    "\n",
    "Data\n",
    "- X: M by dx (100 by 784)\n",
    "- y: M by L by dx (100 by 1 by 784)\n",
    "\n",
    "for calculating total loss by batch\n",
    "- q_mu: M by dz (100 by dz)\n",
    "- q_s2: M by dz (100 by dz)\n",
    "- q_a2: M by dz (100 by dz)\n",
    "\n",
    "for calculating gradients by batch\n",
    "- q_h1: M by dm (100 by dm)\n",
    "- p_h2: M by L by dm (100 by 1 by dm)\n",
    "- z: M by L by dz (100 by 1 by dz)\n",
    "- eps: M by L by dz (100 by 1 by dz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X=(60000, 28, 28), y=(60000,)\n",
      "Test: X=(10000, 28, 28), y=(10000,)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(trainX, trainy), (testX, testy) = mnist.load_data()\n",
    "# summarize loaded dataset\n",
    "print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n",
    "print('Test: X=%s, y=%s' % (testX.shape, testy.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot first few images\n",
    "for i in range(9):\n",
    "    # define subplot\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    # plot raw pixel data\n",
    "    plt.imshow(trainX[i], cmap=plt.get_cmap('gray'))\n",
    "# show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Baseline Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pytz\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Baseline Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are baseline version codes (model v0 in final report). Note that due to changes during optimization, some of the functions are not compatible with later/ final version of the codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Batch(M, trainX, trainy):\n",
    "    \"\"\"randomly sample a mini batch of size M from the training data\"\"\"\n",
    "    \n",
    "    N = trainX.shape[0]\n",
    "    sample = np.random.choice(N,M)\n",
    "    \n",
    "    return trainX[sample], trainy[sample]\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"sigmoid function\"\"\"\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_gradient(x):\n",
    "    \"\"\"gradient of sigmoid function\"\"\"\n",
    "    return x * (1-x)\n",
    "\n",
    "def tanh(x):\n",
    "    \"\"\"tanh function\"\"\"\n",
    "    return np.tanh(x)\n",
    "    \n",
    "def tanh_gradient(x):\n",
    "    \"\"\"gradient of tanh function\"\"\"\n",
    "    return 1-np.power(x,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_random(dx, dm, dz, option = \"xavier\"):\n",
    "    \"\"\"\n",
    "    parameter initialization\n",
    "    xavier initialization for weights\n",
    "    all zero for bias\n",
    "    can be used to initialize all zero variables for ADAM by setting \"option = zeros\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # weights initialization\n",
    "    if option == \"zeros\":\n",
    "        # only for variables in ADAM algorithm, not to be used for true model parameters\n",
    "        q_W1 = np.zeros((dm, dx))\n",
    "        p_W5 = np.zeros((dx, dm))\n",
    "        q_W2 = np.zeros((dz, dm))\n",
    "        q_W3 = np.zeros((dz, dm))\n",
    "        p_W4 = np.zeros((dm, dz))\n",
    "    elif option == \"xavier\":\n",
    "        bound = np.sqrt(6)/ np.sqrt(dx + dm)\n",
    "        q_W1 = np.random.uniform(-bound, bound, (dm, dx))\n",
    "        p_W5 = np.random.uniform(-bound, bound, (dx, dm))\n",
    "        bound = np.sqrt(6)/ np.sqrt(dm + dz)\n",
    "        q_W2 = np.random.uniform(-bound, bound, (dz, dm))\n",
    "        q_W3 = np.random.uniform(-bound, bound, (dz, dm))\n",
    "        p_W4 = np.random.uniform(-bound, bound, (dm, dz))\n",
    "    \n",
    "    # bias initialization\n",
    "    q_b1 = np.zeros((dm, 1))\n",
    "    p_b5 = np.zeros((dx, 1))\n",
    "    q_b2 = np.zeros((dz, 1))\n",
    "    q_b3 = np.zeros((dz, 1))\n",
    "    p_b4 = np.zeros((dm, 1))\n",
    "    \n",
    "    W = [q_W1, q_W2, q_W3, p_W4, p_W5]\n",
    "    b = [q_b1, q_b2, q_b3, p_b4, p_b5]\n",
    "    \n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_loss(X, y, q_a2, q_mu, q_s2):\n",
    "    \"\"\"target total loss function - to minimize\"\"\"\n",
    "    \n",
    "    M = X.shape[0]\n",
    "    L = y.shape[1]\n",
    "    \n",
    "    loss = 0\n",
    "    for iD in range(M):\n",
    "        for iL in range(L):\n",
    "            # reconstruction loss for each sample of latent variable\n",
    "            loss = loss - np.sum(X[iD,] * np.log(y[iD,iL,]) + (1-X[iD,]) * np.log(1-y[iD,iL,])) / L\n",
    "        \n",
    "        # KL divergence/ regularization\n",
    "        loss = loss + np.sum(np.power(q_mu[iD,],2) + q_s2[iD,] - q_a2[iD,] - 1)/2\n",
    "    \n",
    "    return loss / M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_forward(X, W, b):\n",
    "    \"\"\"\n",
    "    encoder forward propagation for each data point\n",
    "    X: dx by 1\n",
    "    \"\"\"\n",
    "    \n",
    "    q_W1, q_W2, q_W3, d,d = W\n",
    "    q_b1, q_b2, q_b3, d,d = b\n",
    "    \n",
    "    q_a1 = q_W1 @ X + q_b1\n",
    "    q_h1 = tanh(q_a1)\n",
    "    q_mu = q_W2 @ q_h1 + q_b2\n",
    "    q_a2 = q_W3 @ q_h1 + q_b3\n",
    "    q_s2 = np.exp(q_a2)\n",
    "    \n",
    "    return q_h1.T, q_a2.T, q_mu.T, q_s2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_z(q_mu, q_s2, eps):\n",
    "    \"\"\"sample z\"\"\"\n",
    "    return q_mu + np.sqrt(q_s2) * eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_forward(W, b, z):\n",
    "    \"\"\"\n",
    "    decoder forward propagation for each data point and each sample latent variable\n",
    "    z: dz by 1\n",
    "    \"\"\"\n",
    "    \n",
    "    d,d,d, p_W4, p_W5 = W\n",
    "    d,d,d, p_b4, p_b5 = b\n",
    "    \n",
    "    p_a3 = p_W4 @ z + p_b4\n",
    "    p_h2 = tanh(p_a3)\n",
    "            \n",
    "    p_a4 = p_W5 @ p_h2 + p_b5\n",
    "    y = sigmoid(p_a4)\n",
    "    \n",
    "    return y.T, p_h2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(X, y, W, b, H, Lt):\n",
    "    \"\"\"\"\n",
    "    batch gradient\n",
    "    inputs:\n",
    "        X: M by dx\n",
    "        y: M by L by dx\n",
    "        W: weights\n",
    "        b: bias\n",
    "        H: q_h1 (M by dm), p_h2 (M by L by dm)\n",
    "        Lt: eps (L by dz), z (M by L by dz), q_s2 (M by dz), q_mu (M by dz)\n",
    "    \"\"\"\n",
    "    q_W1, q_W2, q_W3, p_W4, p_W5 = W\n",
    "    q_b1, q_b2, q_b3, p_b4, p_b5 = b\n",
    "    q_h1, p_h2 = H\n",
    "    q_mu, q_s2, z, eps = Lt\n",
    "    \n",
    "    M = X.shape[0]\n",
    "    L = y.shape[1]\n",
    "    \n",
    "    # initialize gradient variables\n",
    "    \n",
    "    # L: loss; R: regularization; J: total target\n",
    "    dL_dW1 = dJ_dW1 = dR_dW1 = np.zeros_like(q_W1)\n",
    "    dL_db1 = dJ_db1 = dR_db1 = np.zeros_like(q_b1)\n",
    "    dL_dW2 = dJ_dW2 = dR_dW2 = np.zeros_like(q_W2)\n",
    "    dL_db2 = dJ_db2 = dR_db2 = np.zeros_like(q_b2)\n",
    "    dL_dW3 = dJ_dW3 = dR_dW3 = np.zeros_like(q_W3)\n",
    "    dL_db3 = dJ_db3 = dR_db3 = np.zeros_like(q_b3)\n",
    "    dL_dW4 = dJ_dW4 = np.zeros_like(p_W4)\n",
    "    dL_db4 = dJ_db4 = np.zeros_like(p_b4)    \n",
    "    dL_dW5 = dJ_dW5 = np.zeros_like(p_W5)\n",
    "    dL_db5 = dJ_db5 = np.zeros_like(p_b5)\n",
    "    \n",
    "    for iD in range(M):\n",
    "        for iL in range(L):\n",
    "            # back propagation for loss\n",
    "\n",
    "            #L_d4 = (np.divide(y[iD,iL,]-X[iD,], y[iD,iL,] * (1-y[iD,iL,])) * sigmoid_gradient(y[iD,iL,])).reshape(-1,1)\n",
    "            \n",
    "            # simplied L_d4\n",
    "            L_d4 = (y[iD,iL,]-X[iD,]).reshape(-1,1)\n",
    "            dL_dW5 = dL_dW5 + L_d4 @ p_h2[iD,iL,].reshape(1,-1)\n",
    "            dL_db5 = dL_db5 + L_d4\n",
    "            \n",
    "            L_d3 = p_W5.T @ L_d4 * tanh_gradient(p_h2[iD,iL,]).reshape(-1,1)\n",
    "            dL_dW4 = dL_dW4 + L_d3 @ z[iD,iL,].reshape(1,-1)\n",
    "            dL_db4 = dL_db4 + L_d3\n",
    "            \n",
    "            L_d22 = p_W4.T @ L_d3 * eps[iL,].reshape(-1,1) * np.sqrt(q_s2[iD,]).reshape(-1,1) / 2\n",
    "            dL_dW3 = dL_dW3 + L_d22 @ q_h1[iD,].reshape(1,-1)\n",
    "            dL_db3 = dL_db3 + L_d22\n",
    "            \n",
    "            L_d21 = p_W4.T @ L_d3\n",
    "            dL_dW2 = dL_dW2 + L_d21 @ q_h1[iD,].reshape(1,-1)\n",
    "            dL_db2 = dL_db2 + L_d21\n",
    "            \n",
    "            L_d1 = (q_W2.T @ L_d21 + q_W3.T @ L_d22) * tanh_gradient(q_h1[iD,]).reshape(-1,1)\n",
    "            dL_dW1 = dL_dW1 + L_d1 @ X[iD,].reshape(1,-1)\n",
    "            dL_db1 = dL_db1 + L_d1\n",
    "        \n",
    "        # back propagation for regularization\n",
    "        R_d22 = ((q_s2[iD,]-1)/2).reshape(-1,1)\n",
    "        dR_dW3 = dR_dW3 + R_d22 @ q_h1[iD,].reshape(1,-1)\n",
    "        dR_db3 = dR_db3 + R_d22\n",
    "\n",
    "        R_d21 = q_mu[iD,].reshape(-1,1)\n",
    "        dR_dW2 = dR_dW2 + R_d21 @ q_h1[iD,].reshape(1,-1)\n",
    "        dR_db2 = dR_db2 + R_d21\n",
    "\n",
    "        R_d1 = (q_W3.T @ R_d22 + q_W2.T @ R_d21) * tanh_gradient(q_h1[iD,]).reshape(-1,1)\n",
    "        dR_dW1 = dR_dW1 + R_d1 @ X[iD,].reshape(1,-1)\n",
    "        dR_db1 = dR_db1 + R_d1\n",
    "    \n",
    "    dJ_dW1 = dL_dW1 / L / M + dR_dW1 / M\n",
    "    dJ_db1 = dL_db1 / L / M + dR_db1 / M\n",
    "    dJ_dW2 = dL_dW2 / L / M + dR_dW2 / M\n",
    "    dJ_db2 = dL_db2 / L / M + dR_db2 / M    \n",
    "    dJ_dW3 = dL_dW3 / L / M + dR_dW3 / M\n",
    "    dJ_db3 = dL_db3 / L / M + dR_db3 / M\n",
    "    dJ_dW4 = dL_dW4 / L / M\n",
    "    dJ_db4 = dL_db4 / L / M \n",
    "    dJ_dW5 = dL_dW5 / L / M\n",
    "    dJ_db5 = dL_db5 / L / M\n",
    "    \n",
    "    dW = [dJ_dW1, dJ_dW2, dJ_dW3, dJ_dW4, dJ_dW5]\n",
    "    db = [dJ_db1, dJ_db2, dJ_db3, dJ_db4, dJ_db5]\n",
    "    \n",
    "    return dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_forward(Spec, X, W, b, eps):\n",
    "    \"\"\"forward propagation for one batch\"\"\"\n",
    "    d, M, L, d, d, dm, dz, d, d = Spec\n",
    "    \n",
    "    # initialize variables for calculating gradients/ loss by batch\n",
    "    q_h1 = np.zeros((M, dm))\n",
    "    q_mu = np.zeros((M, dz))\n",
    "    q_s2 = np.zeros((M, dz))\n",
    "    q_a2 = np.zeros((M, dz))\n",
    "    p_h2 = np.zeros((M, L, dm))\n",
    "    z = np.zeros((M, L, dz))\n",
    "    y = np.zeros((M, L, dx))\n",
    "    \n",
    "    for iD in range(M):\n",
    "        q_h1[iD,], q_a2[iD,], q_mu[iD,], q_s2[iD,] = encoder_forward(X[iD,].reshape(-1,1), W, b)\n",
    "\n",
    "        for iL in range(L):\n",
    "            z[iD,iL,] = sample_z(q_mu[iD,], q_s2[iD,], eps[iL,])\n",
    "            y[iD,iL,], p_h2[iD,iL,] = decoder_forward(W, b, z[iD,iL,].reshape(-1,1))\n",
    "    \n",
    "    H = [q_h1, p_h2]\n",
    "    Lt = [q_mu, q_s2, z, eps]\n",
    "    loss = total_loss(X, y, q_a2, q_mu, q_s2)\n",
    "    return y, H, Lt, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def para_update(W, b, dW, db, alpha):\n",
    "    \"\"\"update weights and bias for gradient descent\"\"\"\n",
    "    \n",
    "    assert len(W) == len(b) == len(dW) == len(db)\n",
    "    n = len(W)\n",
    "    \n",
    "    for i in range(n):\n",
    "        W[i] = W[i] - alpha * dW[i]\n",
    "        b[i] = b[i] - alpha * db[i]\n",
    "    \n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples(Spec, n, W, b):\n",
    "    \"\"\"plot n number of random sampled figures as well as the model-reconstructed versions\"\"\"\n",
    "    \n",
    "    d, d, L, std_const, dx, dm, dz, d, d = Spec\n",
    "    Spec[1] = n\n",
    "    \n",
    "    batchX, batchy = get_Batch(n, trainX, trainy)\n",
    "    Xdim1, Xdim2 = batchX[0].shape[0], batchX[0].shape[1]\n",
    "    assert dx == Xdim1 * Xdim2\n",
    "    X = batchX.reshape(n, dx) / std_const\n",
    "    eps = np.zeros((L, dz))\n",
    "    \n",
    "    y, d,d,d = batch_forward(Spec, X, W, b, eps)\n",
    "    \n",
    "    for i in range(n):\n",
    "        # define subplot\n",
    "        plt.subplot(330 + 1 + i)\n",
    "        # plot raw pixel data\n",
    "        plt.imshow(batchX[i], cmap=plt.get_cmap('gray'))\n",
    "    # show the figure\n",
    "    plt.show()\n",
    "    \n",
    "    for i in range(n):\n",
    "        # define subplot\n",
    "        plt.subplot(330 + 1 + i)\n",
    "        # plot raw pixel data\n",
    "        plt.imshow(y[i,L-1,].reshape(Xdim1, Xdim2) * std_const, cmap=plt.get_cmap('gray'))\n",
    "    # show the figure\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainX, trainy, Spec, grad, doc = \"\"):\n",
    "    \"\"\"train model with vanila gradient descent\"\"\"\n",
    "    nBatch, M, L, std_const, dx, dm, dz, alpha, nP = Spec\n",
    "    status_file = get_filename(\"status\")\n",
    "    para_file = get_filename(\"parameter\")\n",
    "    \n",
    "    # weights and bias initialization\n",
    "    W, b = init_random(dx, dm, dz)\n",
    "\n",
    "    # loss\n",
    "    loss = np.zeros(nBatch)\n",
    "    \n",
    "    # create status file\n",
    "    update_status(status_file, \"x\", \"Training starts: \" + get_timestamp() + \"\\n\")\n",
    "    \n",
    "    for iB in range(nBatch):\n",
    "        # sample a random batch\n",
    "        batchX, batchy = get_Batch(M, trainX, trainy)\n",
    "        X = batchX.reshape(M, dx) / std_const\n",
    "\n",
    "        # sample random noise for latent variable, assuming each batch uses the same random noise for now\n",
    "        eps = np.random.randn(L, dz)\n",
    "\n",
    "        y, H, Lt, loss[iB] = batch_forward(Spec, X, W, b, eps)\n",
    "\n",
    "        dW, db = grad(X, y, W, b, H, Lt)\n",
    "        W, b = para_update(W, b, dW, db, alpha)\n",
    "        \n",
    "        if (iB+1) % nP == 0:\n",
    "            # append status file\n",
    "            update_status(status_file, \"a\", \"Batch \" + str(iB+1) + \" : \" + get_timestamp() + \"\\n\")\n",
    "    \n",
    "    # save parameter to file\n",
    "    save_para(para_file, doc = doc, Spec = Spec, W = W, b = b, loss = loss)\n",
    "    \n",
    "    return Spec, W, b, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Baseline Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codes used to call baseline version functions for model training. Again due to later changes during optimization, some of these codes might not be compatible to later/ final version of the codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "nBatch = 60000 # number of mini-batch to train\n",
    "M = 100 # batch size\n",
    "L = 1 # sample size\n",
    "std_const = 255 # to standardize data\n",
    "\n",
    "Xdim1, Xdim2 = trainX[0].shape[0], trainX[0].shape[1]\n",
    "dx = Xdim1 * Xdim2 # dimension of the input\n",
    "dm = 500 # dimension of the hidden layer\n",
    "dz = 3 # dimension of latent variable\n",
    "\n",
    "alpha = 0.005 # learning rate\n",
    "\n",
    "nP = 1000 # print out status every nP batches\n",
    "\n",
    "Spec = [nBatch, M, L, std_const, dx, dm, dz, alpha, nP]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example codes to train using Model v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spec, W, b, loss = train(trainX, trainy, Spec, grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are functions used during model developments but not used in anyb way in the final version of the codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_para(filename, **kwargs):\n",
    "    \"\"\"save weights and bias parameters\"\"\"\n",
    "    file = open(filename, 'wb')\n",
    "    pickle.dump(kwargs, file)\n",
    "    file.close()\n",
    "\n",
    "def get_para(filename):\n",
    "    \"\"\"read parameters from file\"\"\"\n",
    "    file = open(filename, 'rb')\n",
    "    dict = pickle.load(file)\n",
    "    return dict\n",
    "\n",
    "def get_filename(suffix=\"\", format = \"%Y_%m_%d_%H_%M_%S\", ext = \".txt\"):\n",
    "    \"\"\"create file name\"\"\"\n",
    "    if suffix != \"\":\n",
    "        suffix = \"_\" + suffix\n",
    "    res = get_timestamp(format = format) + \"_Model_\" + Model_version + suffix + ext\n",
    "    return res\n",
    "\n",
    "def update_status(filename, mode, msg):\n",
    "    \"\"\"for training status update\"\"\"\n",
    "    with open(filename, mode) as f:\n",
    "        f.write(msg)\n",
    "        \n",
    "def get_timestamp(timezone = \"America/New_York\", format = \"%Y/%m/%d %H:%M:%S\"):\n",
    "    \"\"\"formatted date time in local timezone\"\"\"\n",
    "    now = datetime.datetime.now().astimezone(pytz.timezone(\"America/New_York\"))\n",
    "    return now.strftime(format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example codes to save model parameters after model run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc = \"\"\"Second run using ADAM.\"\"\"\n",
    "\n",
    "#filename = get_filename(\"parameter\")\n",
    "#save_para(filename, doc = doc, Spec = Spec, W = W, b = b, loss = loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example codes to read back parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"2020_04_24_15_25_12_Model_v1.1_parameter.txt\"\n",
    "# para = get_para(filename)\n",
    "# doc = para['doc']\n",
    "# W = para['W']\n",
    "# b = para['b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example codes ro continue training using existing parameters (only applies to model version after v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spec, W, b, loss = train_ADAM(trainX, trainy, Spec, grad, W = W, b = b, doc = \"continue run from 2020_04_24_15_25_12 parameter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example codes to plot a few samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_samples(Spec, 9, W, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example codes to plot loss returned by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(loss);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Optimization -- Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are codes for the first implementation of ADAM algorithm (Model v1 in the final report)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ADAM(trainX, trainy, Spec, batch_forward, grad, W = \"\", b = \"\", doc = \"\"):\n",
    "    \"\"\"train model with ADAM\"\"\"\n",
    "    \n",
    "    nBatch, M, L, std_const, dx, dm, dz, alpha, nP = Spec\n",
    "    \n",
    "    if doc != \"\":\n",
    "        status_file = get_filename(\"status\")\n",
    "        para_file = get_filename(\"parameter\")\n",
    "        update_status(status_file, \"x\", \"Training starts: \" + get_timestamp() + \"\\n\")\n",
    "    \n",
    "    # parameters for ADAM algorithm\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "    eps_stable = 1e-8\n",
    "    \n",
    "    # initiate parameters for ADAM\n",
    "    # need to use separate lines of codes otherwise they share the same reference\n",
    "    v_dW, v_db = init_random(dx, dm, dz, option = \"zeros\")\n",
    "    s_dW, s_db = init_random(dx, dm, dz, option = \"zeros\")\n",
    "    vc_dW, vc_db = init_random(dx, dm, dz, option = \"zeros\")\n",
    "    sc_dW, sc_db = init_random(dx, dm, dz, option = \"zeros\")\n",
    "    num_para = len(v_dW)\n",
    "    \n",
    "    # weights and bias initialization\n",
    "    if len(W) == len(b) == 0:\n",
    "        W, b = init_random(dx, dm, dz)\n",
    "\n",
    "    # loss\n",
    "    loss = np.zeros(nBatch)\n",
    "    \n",
    "    for iB in range(nBatch):\n",
    "        # sample a random batch\n",
    "        batchX, batchy = get_Batch(M, trainX, trainy)\n",
    "        X = batchX.reshape(M, dx) / std_const\n",
    "\n",
    "        # sample random noise for latent variable, assuming each batch uses the same random noise for now\n",
    "        eps = np.random.randn(L, dz)\n",
    "\n",
    "        y, H, Lt, loss[iB] = batch_forward(Spec, X, W, b, eps)\n",
    "        dW, db = grad(X, y, W, b, H, Lt)\n",
    "        \n",
    "        # ADAM\n",
    "        for i in range(num_para):\n",
    "            v_dW[i] = beta1*v_dW[i] + (1-beta1)*dW[i]\n",
    "            v_db[i] = beta1*v_db[i] + (1-beta1)*db[i]\n",
    "            s_dW[i] = beta2*s_dW[i] + (1-beta2)*np.power(dW[i],2)\n",
    "            s_db[i] = beta2*s_db[i] + (1-beta2)*np.power(db[i],2)\n",
    "        \n",
    "            vc_dW[i] = v_dW[i]/(1-beta1**(iB+1))\n",
    "            vc_db[i] = v_db[i]/(1-beta1**(iB+1))\n",
    "            sc_dW[i] = s_dW[i]/(1-beta2**(iB+1))\n",
    "            sc_db[i] = s_db[i]/(1-beta2**(iB+1))\n",
    "        \n",
    "            dW[i] = vc_dW[i] / (np.sqrt(sc_dW[i]) + eps_stable)\n",
    "            db[i] = vc_db[i] / (np.sqrt(sc_db[i]) + eps_stable)\n",
    "        \n",
    "        W, b = para_update(W, b, dW, db, alpha)\n",
    "        \n",
    "        if doc != \"\":\n",
    "            if (iB+1) % nP == 0:\n",
    "                # append status file\n",
    "                update_status(status_file, \"a\", \"Batch \" + str(iB+1) + \" : \" + get_timestamp() + \"\\n\")\n",
    "    \n",
    "    # save parameter to file\n",
    "    if doc != \"\":\n",
    "        save_para(para_file, doc = doc, Spec = Spec, W = W, b = b, loss = loss)\n",
    "\n",
    "    return Spec, W, b, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did profiling on Model v1, i.e., baseline codes with ADAM algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pstats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example codes to create profiling file name, change batch size to 100 and proceed with profiling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile_filename = get_filename(\"profiling\", ext = \".prof\")\n",
    "# Spec = [100, M, L, std_const, dx, dm, dz, alpha, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %prun -q -D $profile_filename train_ADAM(trainX, trainy, Spec, grad_nb, doc = \"Profiling grad_nb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example codes to print all the statistics (random order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = pstats.Stats(profile_filename)\n",
    "# p.print_stats()\n",
    "# pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example codes to get statistics sorted by run time. Note that we can specify the specific function to look at by changing inputs in \"print_stats\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p.sort_stats('time', 'cumulative').print_stats(5)\n",
    "# pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p.sort_stats('time', 'cumulative').print_stats('grad')\n",
    "# pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example codes for statistics sorted by number of calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p.sort_stats('ncalls').print_stats(5)\n",
    "# pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "from numba import jit, njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore', category=NumbaDeprecationWarning)\n",
    "warnings.simplefilter('ignore', category=NumbaPendingDeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Minimalist\n",
    "\n",
    "This version is to try to use minimal efforts to speed up (denoted as model v1.5 because it is in between model v1 and v2 referenced by the final report). The goal here is to try make minimal changes to the codes and use numba jit.\n",
    "\n",
    "Naming convension:\n",
    "    - functions which I enviziege will only have one version of numba implementation are named with suffix \"_nb\".\n",
    "    - functions which I realize I'll try other versions of numba implementations (in order to use nopython) are named with suffix \"_nb1\".\n",
    "    \n",
    "Here we try to use *nopython* as much as possible. However, because of the use of heterogeneous lists in the codes for passing parameters, a number of functions can only be jitted under object mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.1 Model v1.5 Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_nb = jit(sigmoid, nopython=True, cache=True)\n",
    "sigmoid_gradient_nb = jit(sigmoid_gradient, nopython=True, cache=True)\n",
    "tanh_nb = jit(tanh, nopython=True, cache=True)\n",
    "tanh_gradient_nb = jit(tanh_gradient, nopython=True, cache=True)\n",
    "total_loss_nb = jit(total_loss, nopython=True, cache=True)\n",
    "sample_z_nb = jit(sample_z, nopython=True, cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def encoder_forward_nb1(X, W, b):\n",
    "    \"\"\"\n",
    "    encoder forward propagation for each data point\n",
    "    X: dx by 1\n",
    "    \"\"\"\n",
    "    \n",
    "    q_W1, q_W2, q_W3, d,d = W\n",
    "    q_b1, q_b2, q_b3, d,d = b\n",
    "    \n",
    "    q_a1 = q_W1 @ X + q_b1\n",
    "    q_h1 = tanh_nb(q_a1)\n",
    "    q_mu = q_W2 @ q_h1 + q_b2\n",
    "    q_a2 = q_W3 @ q_h1 + q_b3\n",
    "    q_s2 = np.exp(q_a2)\n",
    "    \n",
    "    return q_h1.T, q_a2.T, q_mu.T, q_s2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def decoder_forward_nb1(W, b, z):\n",
    "    \"\"\"\n",
    "    decoder forward propagation for each data point and each sample latent variable\n",
    "    z: dz by 1\n",
    "    \"\"\"\n",
    "    \n",
    "    d,d,d, p_W4, p_W5 = W\n",
    "    d,d,d, p_b4, p_b5 = b\n",
    "    \n",
    "    p_a3 = p_W4 @ z + p_b4\n",
    "    p_h2 = tanh_nb(p_a3)\n",
    "            \n",
    "    p_a4 = p_W5 @ p_h2 + p_b5\n",
    "    y = sigmoid_nb(p_a4)\n",
    "    \n",
    "    return y.T, p_h2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(cache=True)\n",
    "def batch_forward_nb1(Spec, X, W, b, eps):\n",
    "    \"\"\"forward propagation for one batch\"\"\"\n",
    "    d, M, L, d, d, dm, dz, d, d = Spec\n",
    "    \n",
    "    # initialize variables for calculating gradients/ loss by batch\n",
    "    q_h1 = np.zeros((M, dm))\n",
    "    q_mu = np.zeros((M, dz))\n",
    "    q_s2 = np.zeros((M, dz))\n",
    "    q_a2 = np.zeros((M, dz))\n",
    "    p_h2 = np.zeros((M, L, dm))\n",
    "    z = np.zeros((M, L, dz))\n",
    "    y = np.zeros((M, L, dx))\n",
    "    \n",
    "    for iD in range(M):\n",
    "        q_h1[iD,], q_a2[iD,], q_mu[iD,], q_s2[iD,] = encoder_forward_nb1(X[iD,].reshape(-1,1), W, b)\n",
    "\n",
    "        for iL in range(L):\n",
    "            z[iD,iL,] = sample_z_nb(q_mu[iD,], q_s2[iD,], eps[iL,])\n",
    "            y[iD,iL,], p_h2[iD,iL,] = decoder_forward_nb1(W, b, z[iD,iL,].reshape(-1,1))\n",
    "    \n",
    "    H = [q_h1, p_h2]\n",
    "    Lt = [q_mu, q_s2, z, eps]\n",
    "    loss = total_loss_nb(X, y, q_a2, q_mu, q_s2)\n",
    "    return (y, H, Lt, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(cache=True)\n",
    "def grad_nb1(X, y, W, b, H, Lt):\n",
    "    \"\"\"\"\n",
    "    batch gradient\n",
    "    inputs:\n",
    "        X: M by dx\n",
    "        y: M by L by dx\n",
    "        W: weights\n",
    "        b: bias\n",
    "        H: q_h1 (M by dm), p_h2 (M by L by dm)\n",
    "        Lt: eps (L by dz), z (M by L by dz), q_s2 (M by dz), q_mu (M by dz)\n",
    "    \"\"\"\n",
    "    q_W1, q_W2, q_W3, p_W4, p_W5 = W\n",
    "    q_b1, q_b2, q_b3, p_b4, p_b5 = b\n",
    "    q_h1, p_h2 = H\n",
    "    q_mu, q_s2, z, eps = Lt\n",
    "    \n",
    "    M = X.shape[0]\n",
    "    L = y.shape[1]\n",
    "    \n",
    "    # initialize gradient variables\n",
    "    \n",
    "    # L: loss; R: regularization; J: total target\n",
    "    dL_dW1 = dJ_dW1 = dR_dW1 = np.zeros_like(q_W1)\n",
    "    dL_db1 = dJ_db1 = dR_db1 = np.zeros_like(q_b1)\n",
    "    dL_dW2 = dJ_dW2 = dR_dW2 = np.zeros_like(q_W2)\n",
    "    dL_db2 = dJ_db2 = dR_db2 = np.zeros_like(q_b2)\n",
    "    dL_dW3 = dJ_dW3 = dR_dW3 = np.zeros_like(q_W3)\n",
    "    dL_db3 = dJ_db3 = dR_db3 = np.zeros_like(q_b3)\n",
    "    dL_dW4 = dJ_dW4 = np.zeros_like(p_W4)\n",
    "    dL_db4 = dJ_db4 = np.zeros_like(p_b4)    \n",
    "    dL_dW5 = dJ_dW5 = np.zeros_like(p_W5)\n",
    "    dL_db5 = dJ_db5 = np.zeros_like(p_b5)\n",
    "    \n",
    "    for iD in range(M):\n",
    "        for iL in range(L):\n",
    "            # back propagation for loss\n",
    "\n",
    "            #L_d4 = (np.divide(y[iD,iL,]-X[iD,], y[iD,iL,] * (1-y[iD,iL,])) * sigmoid_gradient(y[iD,iL,])).reshape(-1,1)\n",
    "            \n",
    "            # simplied L_d4\n",
    "            L_d4 = (y[iD,iL,]-X[iD,]).reshape(-1,1)\n",
    "            dL_dW5 = dL_dW5 + L_d4 @ p_h2[iD,iL,].reshape(1,-1)\n",
    "            dL_db5 = dL_db5 + L_d4\n",
    "            \n",
    "            L_d3 = p_W5.T @ L_d4 * tanh_gradient_nb(p_h2[iD,iL,]).reshape(-1,1)\n",
    "            dL_dW4 = dL_dW4 + L_d3 @ z[iD,iL,].reshape(1,-1)\n",
    "            dL_db4 = dL_db4 + L_d3\n",
    "            \n",
    "            L_d22 = p_W4.T @ L_d3 * eps[iL,].reshape(-1,1) * np.sqrt(q_s2[iD,]).reshape(-1,1) / 2\n",
    "            dL_dW3 = dL_dW3 + L_d22 @ q_h1[iD,].reshape(1,-1)\n",
    "            dL_db3 = dL_db3 + L_d22\n",
    "            \n",
    "            L_d21 = p_W4.T @ L_d3\n",
    "            dL_dW2 = dL_dW2 + L_d21 @ q_h1[iD,].reshape(1,-1)\n",
    "            dL_db2 = dL_db2 + L_d21\n",
    "            \n",
    "            L_d1 = (q_W2.T @ L_d21 + q_W3.T @ L_d22) * tanh_gradient_nb(q_h1[iD,]).reshape(-1,1)\n",
    "            dL_dW1 = dL_dW1 + L_d1 @ X[iD,].reshape(1,-1)\n",
    "            dL_db1 = dL_db1 + L_d1\n",
    "        \n",
    "        # back propagation for regularization\n",
    "        R_d22 = ((q_s2[iD,]-1)/2).reshape(-1,1)\n",
    "        dR_dW3 = dR_dW3 + R_d22 @ q_h1[iD,].reshape(1,-1)\n",
    "        dR_db3 = dR_db3 + R_d22\n",
    "\n",
    "        R_d21 = q_mu[iD,].reshape(-1,1)\n",
    "        dR_dW2 = dR_dW2 + R_d21 @ q_h1[iD,].reshape(1,-1)\n",
    "        dR_db2 = dR_db2 + R_d21\n",
    "\n",
    "        R_d1 = (q_W3.T @ R_d22 + q_W2.T @ R_d21) * tanh_gradient_nb(q_h1[iD,]).reshape(-1,1)\n",
    "        dR_dW1 = dR_dW1 + R_d1 @ X[iD,].reshape(1,-1)\n",
    "        dR_db1 = dR_db1 + R_d1\n",
    "    \n",
    "    dJ_dW1 = dL_dW1 / L / M + dR_dW1 / M\n",
    "    dJ_db1 = dL_db1 / L / M + dR_db1 / M\n",
    "    dJ_dW2 = dL_dW2 / L / M + dR_dW2 / M\n",
    "    dJ_db2 = dL_db2 / L / M + dR_db2 / M    \n",
    "    dJ_dW3 = dL_dW3 / L / M + dR_dW3 / M\n",
    "    dJ_db3 = dL_db3 / L / M + dR_db3 / M\n",
    "    dJ_dW4 = dL_dW4 / L / M\n",
    "    dJ_db4 = dL_db4 / L / M \n",
    "    dJ_dW5 = dL_dW5 / L / M\n",
    "    dJ_db5 = dL_db5 / L / M\n",
    "    \n",
    "    dW = [dJ_dW1, dJ_dW2, dJ_dW3, dJ_dW4, dJ_dW5]\n",
    "    db = [dJ_db1, dJ_db2, dJ_db3, dJ_db4, dJ_db5]\n",
    "    \n",
    "    return dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def train_ADAM_nb1(trainX, trainy, Spec, batch_forward, grad, W = \"\", b = \"\"):\n",
    "    \"\"\"train model with ADAM\"\"\"\n",
    "    \n",
    "    nBatch, M, L, std_const, dx, dm, dz, alpha, nP = Spec\n",
    "    \n",
    "    # parameters for ADAM algorithm\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "    eps_stable = 1e-8\n",
    "    \n",
    "    # initiate parameters for ADAM\n",
    "    # need to use separate lines of codes otherwise they share the same reference\n",
    "    v_dW, v_db = init_random(dx, dm, dz, option = \"zeros\")\n",
    "    s_dW, s_db = init_random(dx, dm, dz, option = \"zeros\")\n",
    "    vc_dW, vc_db = init_random(dx, dm, dz, option = \"zeros\")\n",
    "    sc_dW, sc_db = init_random(dx, dm, dz, option = \"zeros\")\n",
    "    num_para = len(v_dW)\n",
    "    \n",
    "    # weights and bias initialization\n",
    "    if len(W) == len(b) == 0:\n",
    "        W, b = init_random(dx, dm, dz)\n",
    "\n",
    "    # loss\n",
    "    loss = np.zeros(nBatch)\n",
    "    \n",
    "    for iB in range(nBatch):\n",
    "        # sample a random batch\n",
    "        batchX, batchy = get_Batch(M, trainX, trainy)\n",
    "        X = batchX.reshape(M, dx) / std_const\n",
    "\n",
    "        # sample random noise for latent variable, assuming each batch uses the same random noise for now\n",
    "        eps = np.random.randn(L, dz)\n",
    "\n",
    "        y, H, Lt, loss[iB] = batch_forward(Spec, X, W, b, eps)\n",
    "        dW, db = grad(X, y, W, b, H, Lt)\n",
    "        \n",
    "        # ADAM\n",
    "        for i in range(num_para):\n",
    "            v_dW[i] = beta1*v_dW[i] + (1-beta1)*dW[i]\n",
    "            v_db[i] = beta1*v_db[i] + (1-beta1)*db[i]\n",
    "            s_dW[i] = beta2*s_dW[i] + (1-beta2)*np.power(dW[i],2)\n",
    "            s_db[i] = beta2*s_db[i] + (1-beta2)*np.power(db[i],2)\n",
    "        \n",
    "            vc_dW[i] = v_dW[i]/(1-beta1**(iB+1))\n",
    "            vc_db[i] = v_db[i]/(1-beta1**(iB+1))\n",
    "            sc_dW[i] = s_dW[i]/(1-beta2**(iB+1))\n",
    "            sc_db[i] = s_db[i]/(1-beta2**(iB+1))\n",
    "        \n",
    "            dW[i] = vc_dW[i] / (np.sqrt(sc_dW[i]) + eps_stable)\n",
    "            db[i] = vc_db[i] / (np.sqrt(sc_db[i]) + eps_stable)\n",
    "        \n",
    "        W, b = para_update(W, b, dW, db, alpha)\n",
    "\n",
    "    return Spec, W, b, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.2 Model v1.5 Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are codes used for profiling. Currently comma out for documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile_filename = get_filename(\"profiling_v1\", ext = \".prof\")\n",
    "# Spec = [100, M, L, std_const, dx, dm, dz, alpha, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%prun -q -D $profile_filename train_ADAM_nb1(trainX, \\\n",
    "#                                         trainy, Spec, batch_forward_nb1, grad_nb1, doc = \"Optimization v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = pstats.Stats(profile_filename)\n",
    "# p.sort_stats('time', 'cumulative').print_stats(5)\n",
    "# pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Vectorization\n",
    "\n",
    "In this version (Model v2 in the final report), we remove at least the inner loop through vectorization. We first tried to remove the inner loop in the Model v2, i.e., loop for latent variable samples. But soon we realized that since most of the time we only sample $1$ latent variable, removing this loop does not give us much speed up. Therefore we did a second version of vectorization (refer to *grad_vec2*) by removing the loop on sample data and keeping the loop for latent variable sampling. We decided to still keep one layer of looping to ensure calculations do not involve 3-D arrays so as to fully utilize numba later. And because we expect most of the time users will be using $L=1$, keeping the outer loop will not much affect code performance.\n",
    "\n",
    "Note the following:\n",
    "\n",
    "1. part of this version uses the functions already jitted in Model v3, but the main functions (e.g., *batch_forward* and *grad*) are not jitted.\n",
    "2. somehow jit does not work on *grad_vec* even for object mode with error message *\"can't unbox heterogeneous list: array(float64, 2d, C) != array(float64, 3d, C)\".*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2.1 Model v2 Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_forward_vec(X, W, b):\n",
    "    \"\"\"\n",
    "    encoder forward propagation - vectorized version\n",
    "    X: M by dx\n",
    "    q_h1.T: M by dm\n",
    "    q_a2.T: M by dz\n",
    "    q_mu.T: M by dz\n",
    "    q_s2.T: M by dz\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    q_W1, q_W2, q_W3, d,d = W\n",
    "    q_b1, q_b2, q_b3, d,d = b\n",
    "    \n",
    "    q_a1 = q_W1 @ X.T + q_b1 # dm by M\n",
    "    q_h1 = tanh_nb(q_a1) # dm by M\n",
    "    q_mu = q_W2 @ q_h1 + q_b2 # dz by M\n",
    "    q_a2 = q_W3 @ q_h1 + q_b3 # dz by M\n",
    "    q_s2 = np.exp(q_a2) # dz by M\n",
    "    \n",
    "    return q_h1.T, q_a2.T, q_mu.T, q_s2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_z_vec(q_mu, q_s2, eps):\n",
    "    \"\"\"sample latent variable z - vectorized version\"\"\"\n",
    "    \n",
    "    M, dz = q_mu.shape \n",
    "\n",
    "    return q_mu.reshape(M,1,dz) + np.sqrt(q_s2).reshape(M,1,dz) * eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_forward_vec(W, b, z):\n",
    "    \"\"\"\n",
    "    decoder forward propagation - vectorized version\n",
    "    z: M by L by dz\n",
    "    \"\"\"\n",
    "    \n",
    "    d,d,d, p_W4, p_W5 = W\n",
    "    d,d,d, p_b4, p_b5 = b\n",
    "    \n",
    "    p_a3 = z @ p_W4.T + p_b4.T # M by L by dm\n",
    "    p_h2 = tanh_nb(p_a3) # M by L by dm\n",
    "            \n",
    "    p_a4 = p_h2 @ p_W5.T + p_b5.T # M by L by dx\n",
    "    y = sigmoid_nb(p_a4) # M by L by dx\n",
    "    \n",
    "    return y, p_h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_forward_vec(Spec, X, W, b, eps):\n",
    "    \"\"\"forward propagation for one batch - vectorized version\"\"\"\n",
    "    d, M, L, d, d, dm, dz, d, d = Spec\n",
    "    \n",
    "    # initialize variables for calculating gradients/ loss by batch\n",
    "    p_h2 = np.zeros((M, L, dm))\n",
    "    z = np.zeros((M, L, dz))\n",
    "    y = np.zeros((M, L, dx))\n",
    "    \n",
    "    q_h1, q_a2, q_mu, q_s2 = encoder_forward_vec(X, W, b)\n",
    "    z = sample_z_vec(q_mu, q_s2, eps)\n",
    "    y, p_h2 = decoder_forward_vec(W, b, z)\n",
    "    \n",
    "    H = [q_h1, p_h2]\n",
    "    Lt = [q_mu, q_s2, z, eps]\n",
    "    loss = total_loss_vec(X, y, q_a2, q_mu, q_s2)\n",
    "    \n",
    "    return (y, H, Lt, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_vec(X, y, W, b, H, Lt):\n",
    "    \"\"\"\"\n",
    "    batch gradient\n",
    "    inputs:\n",
    "        X: M by dx\n",
    "        y: M by L by dx\n",
    "        W: weights\n",
    "        b: bias\n",
    "        H: q_h1 (M by dm), p_h2 (M by L by dm)\n",
    "        Lt: eps (L by dz), z (M by L by dz), q_s2 (M by dz), q_mu (M by dz)\n",
    "    \"\"\"\n",
    "    q_W1, q_W2, q_W3, p_W4, p_W5 = W\n",
    "    q_b1, q_b2, q_b3, p_b4, p_b5 = b\n",
    "    q_h1, p_h2 = H\n",
    "    q_mu, q_s2, z, eps = Lt\n",
    "    \n",
    "    M = X.shape[0]\n",
    "    L = y.shape[1]\n",
    "    \n",
    "    # initialize gradient variables\n",
    "    \n",
    "    # L: loss; R: regularization; J: total target\n",
    "    dL_dW1 = dJ_dW1 = dR_dW1 = np.zeros_like(q_W1)\n",
    "    dL_db1 = dJ_db1 = dR_db1 = np.zeros_like(q_b1)\n",
    "    dL_dW2 = dJ_dW2 = dR_dW2 = np.zeros_like(q_W2)\n",
    "    dL_db2 = dJ_db2 = dR_db2 = np.zeros_like(q_b2)\n",
    "    dL_dW3 = dJ_dW3 = dR_dW3 = np.zeros_like(q_W3)\n",
    "    dL_db3 = dJ_db3 = dR_db3 = np.zeros_like(q_b3)\n",
    "    dL_dW4 = dJ_dW4 = np.zeros_like(p_W4)\n",
    "    dL_db4 = dJ_db4 = np.zeros_like(p_b4)    \n",
    "    dL_dW5 = dJ_dW5 = np.zeros_like(p_W5)\n",
    "    dL_db5 = dJ_db5 = np.zeros_like(p_b5)\n",
    "    \n",
    "    for iD in range(M):\n",
    "        \n",
    "        # back propagation for loss\n",
    "        L_d4 = y[iD,] - X[iD,].reshape(1,-1) # L by dx\n",
    "        dL_dW5 = dL_dW5 + L_d4.T @ p_h2[iD,] # dx by dm\n",
    "        dL_db5 = dL_db5 + np.sum(L_d4, axis = 0).reshape(-1,1) # dx by 1\n",
    "        \n",
    "        L_d3 = L_d4 @ p_W5 * tanh_gradient_nb(p_h2[iD,]) # L by dm\n",
    "        dL_dW4 = dL_dW4 + L_d3.T @ z[iD,] # dm by dz\n",
    "        dL_db4 = dL_db4 + np.sum(L_d3, axis = 0).reshape(-1,1) # dm by 1\n",
    "        \n",
    "        L_d22 = (np.sum(L_d3 @ p_W4 * eps, axis=0)* np.sqrt(q_s2[iD,]) / 2).reshape(-1,1)  # dz by 1\n",
    "        dL_dW3 = dL_dW3 + L_d22 @ q_h1[iD,].reshape(1,-1) # dz by dm\n",
    "        dL_db3 = dL_db3 + L_d22 # dz by 1\n",
    "        \n",
    "        L_d21 = np.sum(L_d3 @ p_W4, axis = 0).reshape(-1,1) # dz by 1\n",
    "        dL_dW2 = dL_dW2 + L_d21 @ q_h1[iD,].reshape(1,-1) # dz by dm\n",
    "        dL_db2 = dL_db2 + L_d21 # dz by 1\n",
    "        \n",
    "        L_d1 = (q_W2.T @ L_d21 + q_W3.T @ L_d22) * tanh_gradient_nb(q_h1[iD,]).reshape(-1,1) #dm by 1\n",
    "        dL_dW1 = dL_dW1 + L_d1 @ X[iD,].reshape(1,-1) # dm by dx\n",
    "        dL_db1 = dL_db1 + L_d1 # dm by 1\n",
    "\n",
    "        # back propagation for regularization\n",
    "        R_d22 = ((q_s2[iD,]-1)/2).reshape(-1,1)\n",
    "        dR_dW3 = dR_dW3 + R_d22 @ q_h1[iD,].reshape(1,-1)\n",
    "        dR_db3 = dR_db3 + R_d22\n",
    "\n",
    "        R_d21 = q_mu[iD,].reshape(-1,1)\n",
    "        dR_dW2 = dR_dW2 + R_d21 @ q_h1[iD,].reshape(1,-1)\n",
    "        dR_db2 = dR_db2 + R_d21\n",
    "\n",
    "        R_d1 = (q_W3.T @ R_d22 + q_W2.T @ R_d21) * tanh_gradient_nb(q_h1[iD,]).reshape(-1,1)\n",
    "        dR_dW1 = dR_dW1 + R_d1 @ X[iD,].reshape(1,-1)\n",
    "        dR_db1 = dR_db1 + R_d1\n",
    "    \n",
    "    dJ_dW1 = dL_dW1 / L / M + dR_dW1 / M\n",
    "    dJ_db1 = dL_db1 / L / M + dR_db1 / M\n",
    "    dJ_dW2 = dL_dW2 / L / M + dR_dW2 / M\n",
    "    dJ_db2 = dL_db2 / L / M + dR_db2 / M    \n",
    "    dJ_dW3 = dL_dW3 / L / M + dR_dW3 / M\n",
    "    dJ_db3 = dL_db3 / L / M + dR_db3 / M\n",
    "    dJ_dW4 = dL_dW4 / L / M\n",
    "    dJ_db4 = dL_db4 / L / M \n",
    "    dJ_dW5 = dL_dW5 / L / M\n",
    "    dJ_db5 = dL_db5 / L / M\n",
    "    \n",
    "    dW = [dJ_dW1, dJ_dW2, dJ_dW3, dJ_dW4, dJ_dW5]\n",
    "    db = [dJ_db1, dJ_db2, dJ_db3, dJ_db4, dJ_db5]\n",
    "    \n",
    "    return dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_vec2(X, y, W, b, H, Lt):\n",
    "    \"\"\"\"\n",
    "    batch gradient\n",
    "    inputs:\n",
    "        X: M by dx\n",
    "        y: M by L by dx\n",
    "        W: weights\n",
    "        b: bias\n",
    "        H: q_h1 (M by dm), p_h2 (M by L by dm)\n",
    "        Lt: eps (L by dz), z (M by L by dz), q_s2 (M by dz), q_mu (M by dz)\n",
    "    \"\"\"\n",
    "    q_W1, q_W2, q_W3, p_W4, p_W5 = W\n",
    "    q_b1, q_b2, q_b3, p_b4, p_b5 = b\n",
    "    q_h1, p_h2 = H\n",
    "    q_mu, q_s2, z, eps = Lt\n",
    "    \n",
    "    M = X.shape[0]\n",
    "    L = y.shape[1]\n",
    "    \n",
    "    # initialize gradient variables\n",
    "    \n",
    "    # L: loss; R: regularization; J: total target\n",
    "    dL_dW1 = dJ_dW1 = dR_dW1 = np.zeros_like(q_W1)\n",
    "    dL_db1 = dJ_db1 = dR_db1 = np.zeros_like(q_b1)\n",
    "    dL_dW2 = dJ_dW2 = dR_dW2 = np.zeros_like(q_W2)\n",
    "    dL_db2 = dJ_db2 = dR_db2 = np.zeros_like(q_b2)\n",
    "    dL_dW3 = dJ_dW3 = dR_dW3 = np.zeros_like(q_W3)\n",
    "    dL_db3 = dJ_db3 = dR_db3 = np.zeros_like(q_b3)\n",
    "    dL_dW4 = dJ_dW4 = np.zeros_like(p_W4)\n",
    "    dL_db4 = dJ_db4 = np.zeros_like(p_b4)    \n",
    "    dL_dW5 = dJ_dW5 = np.zeros_like(p_W5)\n",
    "    dL_db5 = dJ_db5 = np.zeros_like(p_b5)\n",
    "\n",
    "    # back propagation for loss\n",
    "    for iL in range(L):\n",
    "        y_iL = y[:,iL,:] # M by dx\n",
    "        p_h2_iL = p_h2[:,iL,:] # M by dm\n",
    "        z_iL = z[:,iL,:] # M by dz\n",
    "        \n",
    "        L_d4 = y_iL - X # M by dx\n",
    "        dL_dW5 = dL_dW5 + L_d4.T @ p_h2_iL # dx by dm\n",
    "        dL_db5 = dL_db5 + np.sum(L_d4, axis = 0).reshape(-1,1) # dx by 1\n",
    "        \n",
    "        L_d3 = L_d4 @ p_W5 * tanh_gradient_nb(p_h2_iL) # M by dm\n",
    "        dL_dW4 = dL_dW4 + L_d3.T @ z_iL # dm by dz\n",
    "        dL_db4 = dL_db4 + np.sum(L_d3, axis = 0).reshape(-1,1) # dm by 1\n",
    "        \n",
    "        L_d22 = L_d3 @ p_W4 * eps[iL,] * np.sqrt(q_s2) / 2  # M by dz\n",
    "        dL_dW3 = dL_dW3 + L_d22.T @ q_h1 # dz by dm\n",
    "        dL_db3 = dL_db3 + np.sum(L_d22, axis = 0).reshape(-1,1) # dz by 1\n",
    "        \n",
    "        L_d21 = L_d3 @ p_W4 # M by dz\n",
    "        dL_dW2 = dL_dW2 + L_d21.T @ q_h1 # dz by dm\n",
    "        dL_db2 = dL_db2 + np.sum(L_d21, axis = 0).reshape(-1,1) # dz by 1\n",
    "\n",
    "        L_d1 = (L_d21 @ q_W2 + L_d22 @ q_W3) * tanh_gradient_nb(q_h1) # M by dm\n",
    "        dL_dW1 = dL_dW1 + L_d1.T @ X # dm by dx\n",
    "        dL_db1 = dL_db1 + np.sum(L_d1, axis = 0).reshape(-1,1) # dm by 1\n",
    "\n",
    "    # back propagation for regularization\n",
    "    R_d22 = (q_s2 - 1)/2 # M by dz\n",
    "    dR_dW3 = dR_dW3 + R_d22.T @ q_h1 # dz by dm\n",
    "    dR_db3 = dR_db3 + np.sum(R_d22, axis = 0).reshape(-1,1) # dz by 1\n",
    "    \n",
    "    R_d21 = q_mu # M by dz\n",
    "    dR_dW2 = dR_dW2 + R_d21.T @ q_h1 # dz by dm\n",
    "    dR_db2 = dR_db2 + np.sum(R_d21, axis = 0).reshape(-1,1) # dm by 1\n",
    "\n",
    "    R_d1 = (R_d22 @ q_W3 + R_d21 @ q_W2) * tanh_gradient_nb(q_h1) # M by dm\n",
    "    dR_dW1 = dR_dW1 + R_d1.T @ X # dm by dx\n",
    "    dR_db1 = dR_db1 + np.sum(R_d1, axis = 0).reshape(-1,1) # dm by 1\n",
    "    \n",
    "    dJ_dW1 = dL_dW1 / L / M + dR_dW1 / M\n",
    "    dJ_db1 = dL_db1 / L / M + dR_db1 / M\n",
    "    dJ_dW2 = dL_dW2 / L / M + dR_dW2 / M\n",
    "    dJ_db2 = dL_db2 / L / M + dR_db2 / M    \n",
    "    dJ_dW3 = dL_dW3 / L / M + dR_dW3 / M\n",
    "    dJ_db3 = dL_db3 / L / M + dR_db3 / M\n",
    "    dJ_dW4 = dL_dW4 / L / M\n",
    "    dJ_db4 = dL_db4 / L / M \n",
    "    dJ_dW5 = dL_dW5 / L / M\n",
    "    dJ_db5 = dL_db5 / L / M\n",
    "    \n",
    "    dW = [dJ_dW1, dJ_dW2, dJ_dW3, dJ_dW4, dJ_dW5]\n",
    "    db = [dJ_db1, dJ_db2, dJ_db3, dJ_db4, dJ_db5]\n",
    "    \n",
    "    return dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_loss_vec(X, y, q_a2, q_mu, q_s2):\n",
    "    \"\"\"target total loss function - to minimize - vectorized version\"\"\"\n",
    "    \n",
    "    M, dx, L = X.shape[0], X.shape[1], y.shape[1]\n",
    "    \n",
    "    # reconstruction loss for each sample of latent variable\n",
    "    loss = -np.sum(X.reshape(M,1,dx) * np.log(y) + (1-X.reshape(M,1,dx))* np.log(1-y)) / L\n",
    "    \n",
    "    # KL divergence/ regularization\n",
    "    loss = (loss + np.sum(np.power(q_mu,2) + q_s2 - q_a2 - 1)/2)/M\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2.2 Model v2 Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are codes used for profiling. Currently comma out for documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile_filename = get_filename(\"profiling_v2\", ext = \".prof\")\n",
    "# Spec = [100, M, L, std_const, dx, dm, dz, alpha, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %prun -q -D $profile_filename train_ADAM_nb1(trainX, \\\n",
    "#                                         trainy, Spec, batch_forward_vec, grad_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = pstats.Stats(profile_filename)\n",
    "# p.sort_stats('time', 'cumulative').print_stats(5)\n",
    "# pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Vectorized Numba\n",
    "\n",
    "In this version (Model v2.51 in the report), we try to use numba jit on the vectorized codes in Model v2 as much as possible. \n",
    "\n",
    "We noted that nopython mode cannot be used for matrix multiplication beyond 2-d using \"@\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.1 Model v2.51 Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss_vec_nb = jit(total_loss_vec, nopython=True, cache=True)\n",
    "sample_z_vec_nb = jit(sample_z_vec, nopython=True, cache=True)\n",
    "encoder_forward_vec_nb1 = jit(encoder_forward_vec, nopython=True, cache=True)\n",
    "decoder_forward_vec_nb1 = jit(decoder_forward_vec, cache=True)\n",
    "grad_vec_nb1 = jit(grad_vec, cache=True)\n",
    "grad_vec2_nb1 = jit(grad_vec2, cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(cache=True)\n",
    "def batch_forward_vec_nb1(Spec, X, W, b, eps):\n",
    "    \"\"\"forward propagation for one batch - vectorized version\"\"\"\n",
    "    d, M, L, d, d, dm, dz, d, d = Spec\n",
    "    \n",
    "    # initialize variables for calculating gradients/ loss by batch\n",
    "    p_h2 = np.zeros((M, L, dm))\n",
    "    z = np.zeros((M, L, dz))\n",
    "    y = np.zeros((M, L, dx))\n",
    "    \n",
    "    q_h1, q_a2, q_mu, q_s2 = encoder_forward_vec_nb1(X, W, b)\n",
    "    z = sample_z_vec_nb(q_mu, q_s2, eps)\n",
    "    y, p_h2 = decoder_forward_vec_nb1(W, b, z)\n",
    "    \n",
    "    H = [q_h1, p_h2]\n",
    "    Lt = [q_mu, q_s2, z, eps]\n",
    "    loss = total_loss_vec_nb(X, y, q_a2, q_mu, q_s2)\n",
    "    \n",
    "    return (y, H, Lt, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.2 Model v2.51 Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are codes used for profiling. Currently comma out for documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile_filename = get_filename(\"profiling_v3\", ext = \".prof\")\n",
    "# Spec = [100, M, L, std_const, dx, dm, dz, alpha, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %prun -q -D $profile_filename train_ADAM_nb1(trainX, \\\n",
    "#                                         trainy, Spec, batch_forward_vec_nb1, grad_vec_nb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = pstats.Stats(profile_filename)\n",
    "# p.sort_stats('time', 'cumulative').print_stats(5)\n",
    "# pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Non-vectorized Numba Nopython\n",
    "\n",
    "From the minimalist version (Model v1.5), we noticed that we cannot use *jit nopython* because of the use of heterogeneous lists. In this version we try to remove those lists using the non-vectorized version of codes to see how much speed up it gives us. In this version we also try to use numba jit as much as possible by jitting all the functions.\n",
    "\n",
    "Note the following:\n",
    "\n",
    "1. Naming convension, for all functions for which I needed to make changes in order to break the heterogeneous lists, I name them with suffix \"_nb2\" to distinguish from the previous version of jitted functions\n",
    "2. there are two versions of *train_ADAM* implemented in this section. The first one (*train_ADAM_nb2*) is to avoid using heterogeneous list (as can be seen by the super long lines of codes because we cannot update parameters by looping through them in a list). The second version (*train_ADAM_v2*) is to give up using nopython for *train_ADAM* function and thus keep the same structure as before while utilizaing other functions in this section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.4.1 Model v2.52 Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_Batch_nb = jit(get_Batch, nopython=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def init_random_nb2(dx, dm, dz, option = \"xavier\"):\n",
    "    \"\"\"\n",
    "    parameter random initialization\n",
    "    xavier initialization for parameters\n",
    "    all zero for bias\n",
    "    \"\"\"\n",
    "    \n",
    "    # weights initialization\n",
    "    if option == \"zeros\":\n",
    "        # only for variables in ADAM algorithm, not to be used for true model parameters\n",
    "        q_W1 = np.zeros((dm, dx))\n",
    "        p_W5 = np.zeros((dx, dm))\n",
    "        q_W2 = np.zeros((dz, dm))\n",
    "        q_W3 = np.zeros((dz, dm))\n",
    "        p_W4 = np.zeros((dm, dz))\n",
    "    elif option == \"xavier\":\n",
    "        bound = np.sqrt(6)/ np.sqrt(dx + dm)\n",
    "        q_W1 = np.random.uniform(-bound, bound, (dm, dx))\n",
    "        p_W5 = np.random.uniform(-bound, bound, (dx, dm))\n",
    "        bound = np.sqrt(6)/ np.sqrt(dm + dz)\n",
    "        q_W2 = np.random.uniform(-bound, bound, (dz, dm))\n",
    "        q_W3 = np.random.uniform(-bound, bound, (dz, dm))\n",
    "        p_W4 = np.random.uniform(-bound, bound, (dm, dz))\n",
    "    \n",
    "    # bias initialization\n",
    "    q_b1 = np.zeros((dm, 1))\n",
    "    p_b5 = np.zeros((dx, 1))\n",
    "    q_b2 = np.zeros((dz, 1))\n",
    "    q_b3 = np.zeros((dz, 1))\n",
    "    p_b4 = np.zeros((dm, 1))\n",
    "\n",
    "    return q_W1, q_W2, q_W3, p_W4, p_W5, q_b1, q_b2, q_b3, p_b4, p_b5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def encoder_forward_nb2(X, q_W1, q_W2, q_W3, q_b1, q_b2, q_b3):\n",
    "    \"\"\"\n",
    "    encoder forward propagation for each data point\n",
    "    X: dx by 1\n",
    "    \"\"\"\n",
    "    \n",
    "    q_a1 = q_W1 @ X + q_b1\n",
    "    q_h1 = tanh_nb(q_a1)\n",
    "    q_mu = q_W2 @ q_h1 + q_b2\n",
    "    q_a2 = q_W3 @ q_h1 + q_b3\n",
    "    q_s2 = np.exp(q_a2)\n",
    "    \n",
    "    return q_h1.T, q_a2.T, q_mu.T, q_s2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def decoder_forward_nb2(p_W4, p_W5, p_b4, p_b5, z):\n",
    "    \"\"\"\n",
    "    decoder forward propagation for each data point and each sample latent variable\n",
    "    z: dz by 1\n",
    "    \"\"\"\n",
    "    \n",
    "    p_a3 = p_W4 @ z + p_b4\n",
    "    p_h2 = tanh_nb(p_a3)\n",
    "            \n",
    "    p_a4 = p_W5 @ p_h2 + p_b5\n",
    "    y = sigmoid_nb(p_a4)\n",
    "    \n",
    "    return y.T, p_h2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def batch_forward_nb2(M, L, dm, dz, X, q_W1, q_W2, q_W3, p_W4, p_W5, q_b1, q_b2, q_b3, p_b4, p_b5, eps):\n",
    "    \"\"\"forward propagation for one batch\"\"\"\n",
    "    \n",
    "    # initialize variables for calculating gradients/ loss by batch\n",
    "    q_h1 = np.zeros((M, dm))\n",
    "    q_mu = np.zeros((M, dz))\n",
    "    q_s2 = np.zeros((M, dz))\n",
    "    q_a2 = np.zeros((M, dz))\n",
    "    p_h2 = np.zeros((M, L, dm))\n",
    "    z = np.zeros((M, L, dz))\n",
    "    y = np.zeros((M, L, dx))\n",
    "    \n",
    "    for iD in range(M):\n",
    "        q_h1[iD,], q_a2[iD,], q_mu[iD,], q_s2[iD,] =\\\n",
    "        encoder_forward_nb2(X[iD,].reshape(-1,1), q_W1, q_W2, q_W3, q_b1, q_b2, q_b3)\n",
    "\n",
    "        for iL in range(L):\n",
    "            z[iD,iL,] = sample_z_nb(q_mu[iD,], q_s2[iD,], eps[iL,])\n",
    "            y[iD,iL,], p_h2[iD,iL,] = decoder_forward_nb2(p_W4, p_W5, p_b4, p_b5, z[iD,iL,].reshape(-1,1))\n",
    "    \n",
    "    loss = total_loss_nb(X, y, q_a2, q_mu, q_s2)\n",
    "    \n",
    "    return y, q_h1, p_h2, q_mu, q_s2, z, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def grad_nb2(X, y, q_W1, q_W2, q_W3, p_W4, p_W5, q_b1, q_b2, q_b3, p_b4, p_b5, q_h1, p_h2, q_mu, q_s2, z, eps):\n",
    "    \"\"\"\"\n",
    "    batch gradient\n",
    "    inputs:\n",
    "        X: M by dx\n",
    "        y: M by L by dx\n",
    "        W: weights\n",
    "        b: bias\n",
    "        H: q_h1 (M by dm), p_h2 (M by L by dm)\n",
    "        Lt: eps (L by dz), z (M by L by dz), q_s2 (M by dz), q_mu (M by dz)\n",
    "    \"\"\"\n",
    "    M = X.shape[0]\n",
    "    L = y.shape[1]\n",
    "    \n",
    "    # initialize gradient variables\n",
    "    \n",
    "    # L: loss; R: regularization; J: total target\n",
    "    dL_dW1 = dJ_dW1 = dR_dW1 = np.zeros_like(q_W1)\n",
    "    dL_db1 = dJ_db1 = dR_db1 = np.zeros_like(q_b1)\n",
    "    dL_dW2 = dJ_dW2 = dR_dW2 = np.zeros_like(q_W2)\n",
    "    dL_db2 = dJ_db2 = dR_db2 = np.zeros_like(q_b2)\n",
    "    dL_dW3 = dJ_dW3 = dR_dW3 = np.zeros_like(q_W3)\n",
    "    dL_db3 = dJ_db3 = dR_db3 = np.zeros_like(q_b3)\n",
    "    dL_dW4 = dJ_dW4 = np.zeros_like(p_W4)\n",
    "    dL_db4 = dJ_db4 = np.zeros_like(p_b4)    \n",
    "    dL_dW5 = dJ_dW5 = np.zeros_like(p_W5)\n",
    "    dL_db5 = dJ_db5 = np.zeros_like(p_b5)\n",
    "    \n",
    "    for iD in range(M):\n",
    "        for iL in range(L):\n",
    "            # back propagation for loss\n",
    "\n",
    "            #L_d4 = (np.divide(y[iD,iL,]-X[iD,], y[iD,iL,] * (1-y[iD,iL,])) * sigmoid_gradient(y[iD,iL,])).reshape(-1,1)\n",
    "            \n",
    "            # simplied L_d4\n",
    "            L_d4 = (y[iD,iL,]-X[iD,]).reshape(-1,1)\n",
    "            dL_dW5 = dL_dW5 + L_d4 @ p_h2[iD,iL,].reshape(1,-1)\n",
    "            dL_db5 = dL_db5 + L_d4\n",
    "            \n",
    "            L_d3 = p_W5.T @ L_d4 * tanh_gradient_nb(p_h2[iD,iL,]).reshape(-1,1)\n",
    "            dL_dW4 = dL_dW4 + L_d3 @ z[iD,iL,].reshape(1,-1)\n",
    "            dL_db4 = dL_db4 + L_d3\n",
    "            \n",
    "            L_d22 = p_W4.T @ L_d3 * eps[iL,].reshape(-1,1) * np.sqrt(q_s2[iD,]).reshape(-1,1) / 2\n",
    "            dL_dW3 = dL_dW3 + L_d22 @ q_h1[iD,].reshape(1,-1)\n",
    "            dL_db3 = dL_db3 + L_d22\n",
    "            \n",
    "            L_d21 = p_W4.T @ L_d3\n",
    "            dL_dW2 = dL_dW2 + L_d21 @ q_h1[iD,].reshape(1,-1)\n",
    "            dL_db2 = dL_db2 + L_d21\n",
    "            \n",
    "            L_d1 = (q_W2.T @ L_d21 + q_W3.T @ L_d22) * tanh_gradient_nb(q_h1[iD,]).reshape(-1,1)\n",
    "            dL_dW1 = dL_dW1 + L_d1 @ X[iD,].reshape(1,-1)\n",
    "            dL_db1 = dL_db1 + L_d1\n",
    "        \n",
    "        # back propagation for regularization\n",
    "        R_d22 = ((q_s2[iD,]-1)/2).reshape(-1,1)\n",
    "        dR_dW3 = dR_dW3 + R_d22 @ q_h1[iD,].reshape(1,-1)\n",
    "        dR_db3 = dR_db3 + R_d22\n",
    "\n",
    "        R_d21 = q_mu[iD,].reshape(-1,1)\n",
    "        dR_dW2 = dR_dW2 + R_d21 @ q_h1[iD,].reshape(1,-1)\n",
    "        dR_db2 = dR_db2 + R_d21\n",
    "\n",
    "        R_d1 = (q_W3.T @ R_d22 + q_W2.T @ R_d21) * tanh_gradient_nb(q_h1[iD,]).reshape(-1,1)\n",
    "        dR_dW1 = dR_dW1 + R_d1 @ X[iD,].reshape(1,-1)\n",
    "        dR_db1 = dR_db1 + R_d1\n",
    "    \n",
    "    dJ_dW1 = dL_dW1 / L / M + dR_dW1 / M\n",
    "    dJ_db1 = dL_db1 / L / M + dR_db1 / M\n",
    "    dJ_dW2 = dL_dW2 / L / M + dR_dW2 / M\n",
    "    dJ_db2 = dL_db2 / L / M + dR_db2 / M    \n",
    "    dJ_dW3 = dL_dW3 / L / M + dR_dW3 / M\n",
    "    dJ_db3 = dL_db3 / L / M + dR_db3 / M\n",
    "    dJ_dW4 = dL_dW4 / L / M\n",
    "    dJ_db4 = dL_db4 / L / M \n",
    "    dJ_dW5 = dL_dW5 / L / M\n",
    "    dJ_db5 = dL_db5 / L / M\n",
    "    \n",
    "    return dJ_dW1, dJ_dW2, dJ_dW3, dJ_dW4, dJ_dW5, dJ_db1, dJ_db2, dJ_db3, dJ_db4, dJ_db5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def train_ADAM_nb2(trainX, trainy, nBatch, M, L, std_const, dx, dm, dz, alpha, batch_forward, grad):\n",
    "    \"\"\"train model with ADAM\"\"\"\n",
    "\n",
    "    # parameters for ADAM algorithm\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "    eps_stable = 1e-8\n",
    "    \n",
    "    # initiate parameters for ADAM\n",
    "    # need to use separate lines of codes otherwise they share the same reference\n",
    "    v_dW1, v_dW2, v_dW3, v_dW4, v_dW5, v_db1, v_db2, v_db3, v_db4, v_db5 = \\\n",
    "    init_random_nb2(dx, dm, dz, option = \"zeros\")\n",
    "    s_dW1, s_dW2, s_dW3, s_dW4, s_dW5, s_db1, s_db2, s_db3, s_db4, s_db5 = \\\n",
    "    init_random_nb2(dx, dm, dz, option = \"zeros\")\n",
    "    vc_dW1, vc_dW2, vc_dW3, vc_dW4, vc_dW5, vc_db1, vc_db2, vc_db3, vc_db4, vc_db5 = \\\n",
    "    init_random_nb2(dx, dm, dz, option = \"zeros\")\n",
    "    sc_dW1, sc_dW2, sc_dW3, sc_dW4, sc_dW5, sc_db1, sc_db2, sc_db3, sc_db4, sc_db5 = \\\n",
    "    init_random_nb2(dx, dm, dz, option = \"zeros\")\n",
    "    \n",
    "    # weights and bias initialization\n",
    "    W1, W2, W3, W4, W5, b1, b2, b3, b4, b5 = init_random_nb2(dx, dm, dz)\n",
    "\n",
    "    # loss\n",
    "    loss = np.zeros(nBatch)\n",
    "    \n",
    "    for iB in range(nBatch):\n",
    "        # sample a random batch\n",
    "        batchX, batchy = get_Batch_nb(M, trainX, trainy)\n",
    "        X = batchX.reshape(M, dx) / std_const\n",
    "\n",
    "        # sample random noise for latent variable, assuming each batch uses the same random noise for now\n",
    "        eps = np.random.randn(L, dz)\n",
    "\n",
    "        y, q_h1, p_h2, q_mu, q_s2, z, loss[iB] = \\\n",
    "        batch_forward(M, L, dm, dz, X, W1, W2, W3, W4, W5, b1, b2, b3, b4, b5, eps)\n",
    "\n",
    "        dW1, dW2, dW3, dW4, dW5, db1, db2, db3, db4, db5 = \\\n",
    "        grad(X, y, W1, W2, W3, W4, W5, b1, b2, b3, b4, b5, q_h1, p_h2, q_mu, q_s2, z, eps)\n",
    "        \n",
    "        # ADAM\n",
    "        v_dW1 = beta1*v_dW1 + (1-beta1)*dW1\n",
    "        v_dW2 = beta1*v_dW2 + (1-beta1)*dW2\n",
    "        v_dW3 = beta1*v_dW3 + (1-beta1)*dW3\n",
    "        v_dW4 = beta1*v_dW4 + (1-beta1)*dW4\n",
    "        v_dW5 = beta1*v_dW5 + (1-beta1)*dW5\n",
    "        \n",
    "        v_db1 = beta1*v_db1 + (1-beta1)*db1\n",
    "        v_db2 = beta1*v_db2 + (1-beta1)*db2\n",
    "        v_db3 = beta1*v_db3 + (1-beta1)*db3\n",
    "        v_db4 = beta1*v_db4 + (1-beta1)*db4\n",
    "        v_db5 = beta1*v_db5 + (1-beta1)*db5\n",
    "        \n",
    "        s_dW1 = beta2*s_dW1 + (1-beta2)*np.power(dW1,2)\n",
    "        s_dW2 = beta2*s_dW2 + (1-beta2)*np.power(dW2,2)\n",
    "        s_dW3 = beta2*s_dW3 + (1-beta2)*np.power(dW3,2)\n",
    "        s_dW4 = beta2*s_dW4 + (1-beta2)*np.power(dW4,2)\n",
    "        s_dW5 = beta2*s_dW5 + (1-beta2)*np.power(dW5,2)\n",
    "        \n",
    "        s_db1 = beta2*s_db1 + (1-beta2)*np.power(db1,2)\n",
    "        s_db2 = beta2*s_db2 + (1-beta2)*np.power(db2,2)\n",
    "        s_db3 = beta2*s_db3 + (1-beta2)*np.power(db3,2)\n",
    "        s_db4 = beta2*s_db4 + (1-beta2)*np.power(db4,2)\n",
    "        s_db5 = beta2*s_db5 + (1-beta2)*np.power(db5,2)\n",
    "        \n",
    "        vc_dW1 = v_dW1/(1-beta1**(iB+1))\n",
    "        vc_dW2 = v_dW2/(1-beta1**(iB+1))\n",
    "        vc_dW3 = v_dW3/(1-beta1**(iB+1))\n",
    "        vc_dW4 = v_dW4/(1-beta1**(iB+1))\n",
    "        vc_dW5 = v_dW5/(1-beta1**(iB+1))\n",
    "        \n",
    "        vc_db1 = v_db1/(1-beta1**(iB+1))\n",
    "        vc_db2 = v_db2/(1-beta1**(iB+1))\n",
    "        vc_db3 = v_db3/(1-beta1**(iB+1))\n",
    "        vc_db4 = v_db4/(1-beta1**(iB+1))\n",
    "        vc_db5 = v_db5/(1-beta1**(iB+1))\n",
    "        \n",
    "        sc_dW1 = s_dW1/(1-beta2**(iB+1))\n",
    "        sc_dW2 = s_dW2/(1-beta2**(iB+1))\n",
    "        sc_dW3 = s_dW3/(1-beta2**(iB+1))\n",
    "        sc_dW4 = s_dW4/(1-beta2**(iB+1))\n",
    "        sc_dW5 = s_dW5/(1-beta2**(iB+1))\n",
    "        \n",
    "        sc_db1 = s_db1/(1-beta2**(iB+1))\n",
    "        sc_db2 = s_db2/(1-beta2**(iB+1))\n",
    "        sc_db3 = s_db3/(1-beta2**(iB+1))\n",
    "        sc_db4 = s_db4/(1-beta2**(iB+1))\n",
    "        sc_db5 = s_db5/(1-beta2**(iB+1))\n",
    "        \n",
    "        dW1 = vc_dW1 / (np.sqrt(sc_dW1) + eps_stable)\n",
    "        dW2 = vc_dW2 / (np.sqrt(sc_dW2) + eps_stable)\n",
    "        dW3 = vc_dW3 / (np.sqrt(sc_dW3) + eps_stable)\n",
    "        dW4 = vc_dW4 / (np.sqrt(sc_dW4) + eps_stable)\n",
    "        dW5 = vc_dW5 / (np.sqrt(sc_dW5) + eps_stable)\n",
    "        \n",
    "        db1 = vc_db1 / (np.sqrt(sc_db1) + eps_stable)\n",
    "        db2 = vc_db2 / (np.sqrt(sc_db2) + eps_stable)\n",
    "        db3 = vc_db3 / (np.sqrt(sc_db3) + eps_stable)\n",
    "        db4 = vc_db4 / (np.sqrt(sc_db4) + eps_stable)\n",
    "        db5 = vc_db5 / (np.sqrt(sc_db5) + eps_stable)\n",
    "        \n",
    "        W1 = W1 - alpha * dW1\n",
    "        W2 = W2 - alpha * dW2\n",
    "        W3 = W3 - alpha * dW3\n",
    "        W4 = W4 - alpha * dW4\n",
    "        W5 = W5 - alpha * dW5\n",
    "        \n",
    "        b1 = b1 - alpha * db1\n",
    "        b2 = b2 - alpha * db2\n",
    "        b3 = b3 - alpha * db3\n",
    "        b4 = b4 - alpha * db4\n",
    "        b5 = b5 - alpha * db5\n",
    "\n",
    "    return W1, W2, W3, W4, W5, b1, b2, b3, b4, b5, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ADAM_v2(trainX, trainy, Spec, batch_forward, grad, W = \"\", b = \"\", doc = \"\"):\n",
    "    \"\"\"train model with ADAM\"\"\"\n",
    "    \n",
    "    nBatch, M, L, std_const, dx, dm, dz, alpha, nP = Spec\n",
    "    \n",
    "    if doc != \"\":\n",
    "        status_file = get_filename(\"status\")\n",
    "        para_file = get_filename(\"parameter\")\n",
    "        update_status(status_file, \"x\", \"Training starts: \" + get_timestamp() + \"\\n\")\n",
    "    \n",
    "    # parameters for ADAM algorithm\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "    eps_stable = 1e-8\n",
    "    \n",
    "    # initiate parameters for ADAM\n",
    "    # need to use separate lines of codes otherwise they share the same reference\n",
    "    v_dW, v_db = init_random(dx, dm, dz, option = \"zeros\")\n",
    "    s_dW, s_db = init_random(dx, dm, dz, option = \"zeros\")\n",
    "    vc_dW, vc_db = init_random(dx, dm, dz, option = \"zeros\")\n",
    "    sc_dW, sc_db = init_random(dx, dm, dz, option = \"zeros\")\n",
    "    num_para = len(v_dW)\n",
    "    \n",
    "    # weights and bias initialization\n",
    "    if len(W) == len(b) == 0:\n",
    "        W, b = init_random(dx, dm, dz)\n",
    "        q_W1, q_W2, q_W3, p_W4, p_W5 = W\n",
    "        q_b1, q_b2, q_b3, p_b4, p_b5 = b\n",
    "\n",
    "    # loss\n",
    "    loss = np.zeros(nBatch)\n",
    "    \n",
    "    for iB in range(nBatch):\n",
    "        # sample a random batch\n",
    "        batchX, batchy = get_Batch_nb(M, trainX, trainy)\n",
    "        X = batchX.reshape(M, dx) / std_const\n",
    "\n",
    "        # sample random noise for latent variable, assuming each batch uses the same random noise for now\n",
    "        eps = np.random.randn(L, dz)\n",
    "\n",
    "        y, q_h1, p_h2, q_mu, q_s2, z, loss[iB] = \\\n",
    "        batch_forward(M, L, dm, dz, X, q_W1, q_W2, q_W3, p_W4, p_W5, q_b1, q_b2, q_b3, p_b4, p_b5, eps)\n",
    "        dW1, dW2, dW3, dW4, dW5, db1, db2, db3, db4, db5 = \\\n",
    "        grad(X, y, q_W1, q_W2, q_W3, p_W4, p_W5, q_b1, q_b2, q_b3, p_b4, p_b5, q_h1, p_h2, q_mu, q_s2, z, eps)\n",
    "        \n",
    "        dW = [dW1, dW2, dW3, dW4, dW5]\n",
    "        db = [db1, db2, db3, db4, db5]\n",
    "        \n",
    "        # ADAM\n",
    "        for i in range(num_para):\n",
    "            v_dW[i] = beta1*v_dW[i] + (1-beta1)*dW[i]\n",
    "            v_db[i] = beta1*v_db[i] + (1-beta1)*db[i]\n",
    "            s_dW[i] = beta2*s_dW[i] + (1-beta2)*np.power(dW[i],2)\n",
    "            s_db[i] = beta2*s_db[i] + (1-beta2)*np.power(db[i],2)\n",
    "        \n",
    "            vc_dW[i] = v_dW[i]/(1-beta1**(iB+1))\n",
    "            vc_db[i] = v_db[i]/(1-beta1**(iB+1))\n",
    "            sc_dW[i] = s_dW[i]/(1-beta2**(iB+1))\n",
    "            sc_db[i] = s_db[i]/(1-beta2**(iB+1))\n",
    "        \n",
    "            dW[i] = vc_dW[i] / (np.sqrt(sc_dW[i]) + eps_stable)\n",
    "            db[i] = vc_db[i] / (np.sqrt(sc_db[i]) + eps_stable)\n",
    "        \n",
    "        W, b = para_update(W, b, dW, db, alpha)\n",
    "        \n",
    "        if doc != \"\":\n",
    "            if (iB+1) % nP == 0:\n",
    "                # append status file\n",
    "                update_status(status_file, \"a\", \"Batch \" + str(iB+1) + \" : \" + get_timestamp() + \"\\n\")\n",
    "    \n",
    "    # save parameter to file\n",
    "    if doc != \"\":\n",
    "        save_para(para_file, doc = doc, Spec = Spec, W = W, b = b, loss = loss)\n",
    "\n",
    "    return Spec, W, b, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.4.2 Model v2.52 Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are codes used for profiling. Currently comma out for documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile_filename = get_filename(\"profiling_v4\", ext = \".prof\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %prun -q -D $profile_filename train_ADAM_nb2(\\\n",
    "#            trainX, trainy, 100, M, L, std_const, dx, dm, dz, alpha, batch_forward_nb2, grad_nb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = pstats.Stats(profile_filename)\n",
    "# p.sort_stats('time', 'cumulative').print_stats(5)\n",
    "# pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 Vectorized Numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our prelim final version (Model v3). In this version we combine the knowledge learned while working on all previous versions so as to have the maximum speed up with practical implementations:\n",
    "\n",
    "1. Vectorization gives great speed up therefore we use the vectorized version (along the dimension of looping over sample data)\n",
    "2. nopython can help us maximize numba jit performance therefore we try to use nopython whenever we can, except for the following two functions\n",
    "\n",
    "    - *batch_forward*: we cannot use nopython because it involves calculation and passing of a 3-D variable\n",
    "    - *train_ADAM*: in order to enable nopython we will have to avoid using heterogeneous lists completely which greatly reduces the readability of the codes and increases difficulties on maintenance. Therefore we have decided to keep it in the same format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.5.1 Model v3 Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_random_nb1 = jit(init_random, nopython=True)\n",
    "para_update_nb = jit(para_update, nopython=True, cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(cache=True)\n",
    "def batch_forward_vec_nb2(Spec, X, W, b, eps):\n",
    "    \"\"\"forward propagation for one mini batch - full vectorized version\"\"\"\n",
    "    d, M, L, d, dx, dm, dz, d, d = Spec\n",
    "\n",
    "    p_h2 = np.zeros((M, L, dm))\n",
    "    z = np.zeros((M, L, dz))\n",
    "    y = np.zeros((M, L, dx))\n",
    "    \n",
    "    q_h1, q_a2, q_mu, q_s2 = encoder_forward_vec_nb1(X, W, b) # M by dm, M by dz, M by dz, M by dz\n",
    "    z = sample_z_vec_nb(q_mu, q_s2, eps)\n",
    "    y, p_h2 = decoder_forward_vec_nb1(W, b, z)\n",
    "    \n",
    "    loss = total_loss_vec_nb(X, y, q_a2, q_mu, q_s2)\n",
    "\n",
    "    return y, q_h1, p_h2, q_mu, q_s2, z, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def grad_vec2_nb2(X, y, q_W1, q_W2, q_W3, p_W4, p_W5, q_b1, q_b2, q_b3, p_b4, p_b5, q_h1, p_h2, q_mu, q_s2, z, eps):\n",
    "    \"\"\"\"\n",
    "    batch gradient calculation - vectorized version\n",
    "    not using lists for parameters to enable numba nopython\n",
    "    \n",
    "    inputs:\n",
    "        X: Data [M by dx]\n",
    "        y: Model results [M by L by dx]\n",
    "        q_W1, q_W2, q_W3: Weights for encoder\n",
    "        p_W4, p_W5: Weights for decoder\n",
    "        q_b1, q_b2, q_b3: Bias for encoder\n",
    "        p_b4, p_b5: Bias for decoder\n",
    "        q_h1 (M by dm), p_h2 (M by L by dm): intermediate activation variables\n",
    "        eps (L by dz), z (M by L by dz), q_s2 (M by dz), q_mu (M by dz): for sampling latent variables from posterior\n",
    "    \"\"\"\n",
    "    \n",
    "    M = X.shape[0]\n",
    "    L = y.shape[1]\n",
    "    \n",
    "    # initialize gradient variables\n",
    "    \n",
    "    # L: loss; R: regularization; J: total target\n",
    "    dL_dW1 = dJ_dW1 = dR_dW1 = np.zeros_like(q_W1)\n",
    "    dL_db1 = dJ_db1 = dR_db1 = np.zeros_like(q_b1)\n",
    "    dL_dW2 = dJ_dW2 = dR_dW2 = np.zeros_like(q_W2)\n",
    "    dL_db2 = dJ_db2 = dR_db2 = np.zeros_like(q_b2)\n",
    "    dL_dW3 = dJ_dW3 = dR_dW3 = np.zeros_like(q_W3)\n",
    "    dL_db3 = dJ_db3 = dR_db3 = np.zeros_like(q_b3)\n",
    "    dL_dW4 = dJ_dW4 = np.zeros_like(p_W4)\n",
    "    dL_db4 = dJ_db4 = np.zeros_like(p_b4)    \n",
    "    dL_dW5 = dJ_dW5 = np.zeros_like(p_W5)\n",
    "    dL_db5 = dJ_db5 = np.zeros_like(p_b5)\n",
    "\n",
    "    # back propagation for loss\n",
    "    for iL in range(L):\n",
    "        y_iL = y[:,iL,:] # M by dx\n",
    "        p_h2_iL = p_h2[:,iL,:] # M by dm\n",
    "        z_iL = z[:,iL,:] # M by dz\n",
    "        \n",
    "        L_d4 = y_iL - X # M by dx\n",
    "        dL_dW5 = dL_dW5 + L_d4.T @ p_h2_iL # dx by dm\n",
    "        dL_db5 = dL_db5 + np.sum(L_d4, axis = 0).reshape(-1,1) # dx by 1\n",
    "        \n",
    "        L_d3 = L_d4 @ p_W5 * tanh_gradient_nb(p_h2_iL) # M by dm\n",
    "        dL_dW4 = dL_dW4 + L_d3.T @ z_iL # dm by dz\n",
    "        dL_db4 = dL_db4 + np.sum(L_d3, axis = 0).reshape(-1,1) # dm by 1\n",
    "        \n",
    "        L_d22 = L_d3 @ p_W4 * eps[iL,] * np.sqrt(q_s2) / 2  # M by dz\n",
    "        dL_dW3 = dL_dW3 + L_d22.T @ q_h1 # dz by dm\n",
    "        dL_db3 = dL_db3 + np.sum(L_d22, axis = 0).reshape(-1,1) # dz by 1\n",
    "        \n",
    "        L_d21 = L_d3 @ p_W4 # M by dz\n",
    "        dL_dW2 = dL_dW2 + L_d21.T @ q_h1 # dz by dm\n",
    "        dL_db2 = dL_db2 + np.sum(L_d21, axis = 0).reshape(-1,1) # dz by 1\n",
    "\n",
    "        L_d1 = (L_d21 @ q_W2 + L_d22 @ q_W3) * tanh_gradient_nb(q_h1) # M by dm\n",
    "        dL_dW1 = dL_dW1 + L_d1.T @ X # dm by dx\n",
    "        dL_db1 = dL_db1 + np.sum(L_d1, axis = 0).reshape(-1,1) # dm by 1\n",
    "\n",
    "    # back propagation for regularization\n",
    "    R_d22 = (q_s2 - 1)/2 # M by dz\n",
    "    dR_dW3 = dR_dW3 + R_d22.T @ q_h1 # dz by dm\n",
    "    dR_db3 = dR_db3 + np.sum(R_d22, axis = 0).reshape(-1,1) # dz by 1\n",
    "    \n",
    "    R_d21 = q_mu # M by dz\n",
    "    dR_dW2 = dR_dW2 + R_d21.T @ q_h1 # dz by dm\n",
    "    dR_db2 = dR_db2 + np.sum(R_d21, axis = 0).reshape(-1,1) # dm by 1\n",
    "\n",
    "    R_d1 = (R_d22 @ q_W3 + R_d21 @ q_W2) * tanh_gradient_nb(q_h1) # M by dm\n",
    "    dR_dW1 = dR_dW1 + R_d1.T @ X # dm by dx\n",
    "    dR_db1 = dR_db1 + np.sum(R_d1, axis = 0).reshape(-1,1) # dm by 1\n",
    "    \n",
    "    dJ_dW1 = dL_dW1 / L / M + dR_dW1 / M\n",
    "    dJ_db1 = dL_db1 / L / M + dR_db1 / M\n",
    "    dJ_dW2 = dL_dW2 / L / M + dR_dW2 / M\n",
    "    dJ_db2 = dL_db2 / L / M + dR_db2 / M    \n",
    "    dJ_dW3 = dL_dW3 / L / M + dR_dW3 / M\n",
    "    dJ_db3 = dL_db3 / L / M + dR_db3 / M\n",
    "    dJ_dW4 = dL_dW4 / L / M\n",
    "    dJ_db4 = dL_db4 / L / M \n",
    "    dJ_dW5 = dL_dW5 / L / M\n",
    "    dJ_db5 = dL_db5 / L / M\n",
    "    \n",
    "    return dJ_dW1, dJ_dW2, dJ_dW3, dJ_dW4, dJ_dW5, dJ_db1, dJ_db2, dJ_db3, dJ_db4, dJ_db5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(cache=True)\n",
    "def train_ADAM_nb1_pl(trainX, trainy, Spec, batch_forward, grad, W = \"\", b = \"\"):\n",
    "    \"\"\"train model with ADAM\"\"\"\n",
    "    \n",
    "    nBatch, M, L, std_const, dx, dm, dz, alpha, nP = Spec\n",
    "    \n",
    "    # parameters for ADAM algorithm\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "    eps_stable = 1e-8\n",
    "    \n",
    "    # initiate parameters for ADAM\n",
    "    # need to use separate lines of codes otherwise they share the same reference\n",
    "    v_dW, v_db = init_random_nb1(dx, dm, dz, option = \"zeros\")\n",
    "    s_dW, s_db = init_random_nb1(dx, dm, dz, option = \"zeros\")\n",
    "    vc_dW, vc_db = init_random_nb1(dx, dm, dz, option = \"zeros\")\n",
    "    sc_dW, sc_db = init_random_nb1(dx, dm, dz, option = \"zeros\")\n",
    "    num_para = len(v_dW)\n",
    "    \n",
    "    # weights and bias initialization\n",
    "    if len(W) == len(b) == 0:\n",
    "        W, b = init_random_nb1(dx, dm, dz)\n",
    "    \n",
    "    q_W1, q_W2, q_W3, p_W4, p_W5 = W\n",
    "    q_b1, q_b2, q_b3, p_b4, p_b5 = b\n",
    "\n",
    "    # loss\n",
    "    loss = np.zeros(nBatch)\n",
    "    \n",
    "    for iB in range(nBatch):\n",
    "        # sample a random batch\n",
    "        batchX, batchy = get_Batch_nb(M, trainX, trainy)\n",
    "        X = batchX.reshape(M, dx) / std_const\n",
    "\n",
    "        # sample random noise for latent variable, assuming each batch uses the same random noise for now\n",
    "        eps = np.random.randn(L, dz)\n",
    "\n",
    "        y, q_h1, p_h2, q_mu, q_s2, z, loss[iB] = batch_forward(Spec, X, W, b, eps)\n",
    "        \n",
    "        dJ_dW1, dJ_dW2, dJ_dW3, dJ_dW4, dJ_dW5, dJ_db1, dJ_db2, dJ_db3, dJ_db4, dJ_db5 =\\\n",
    "        grad(X, y, q_W1, q_W2, q_W3, p_W4, p_W5, q_b1, q_b2, q_b3, p_b4, p_b5, q_h1, p_h2, q_mu, q_s2, z, eps)\n",
    "        \n",
    "        dW = [dJ_dW1, dJ_dW2, dJ_dW3, dJ_dW4, dJ_dW5]\n",
    "        db = [dJ_db1, dJ_db2, dJ_db3, dJ_db4, dJ_db5]\n",
    "        \n",
    "        # ADAM\n",
    "        for i in range(num_para):\n",
    "            v_dW[i] = beta1*v_dW[i] + (1-beta1)*dW[i]\n",
    "            v_db[i] = beta1*v_db[i] + (1-beta1)*db[i]\n",
    "            s_dW[i] = beta2*s_dW[i] + (1-beta2)*np.power(dW[i],2)\n",
    "            s_db[i] = beta2*s_db[i] + (1-beta2)*np.power(db[i],2)\n",
    "        \n",
    "            vc_dW[i] = v_dW[i]/(1-beta1**(iB+1))\n",
    "            vc_db[i] = v_db[i]/(1-beta1**(iB+1))\n",
    "            sc_dW[i] = s_dW[i]/(1-beta2**(iB+1))\n",
    "            sc_db[i] = s_db[i]/(1-beta2**(iB+1))\n",
    "        \n",
    "            dW[i] = vc_dW[i] / (np.sqrt(sc_dW[i]) + eps_stable)\n",
    "            db[i] = vc_db[i] / (np.sqrt(sc_db[i]) + eps_stable)\n",
    "        \n",
    "        W, b = para_update_nb(W, b, dW, db, alpha)\n",
    "\n",
    "    return Spec, W, b, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.5.2 Model v3 Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are codes used for profiling. Currently comma out for documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile_filename = get_filename(\"profiling_v5\", ext = \".prof\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %prun -q -D $profile_filename train_ADAM_nb1_pl(\\\n",
    "#            trainX, trainy, Spec, batch_forward_vec_nb2, grad_vec2_nb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = pstats.Stats(profile_filename)\n",
    "# p.sort_stats('time', 'cumulative').print_stats(5)\n",
    "# pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6 Model Correction\n",
    "\n",
    "While working on the final report, VR noted that the current implementation uses the latent variable sample for all training data in a mini-batch. Theoretically this is not mathematically correct, and we suspect this is the reason for some weird patterns in the training results, for example, instead of the consistent decreasing trend we previously saw when train_ADAM was first implemented, the loss plot from the final model shows rather large fluctuation.\n",
    "\n",
    "For this version I start with the final codings.\n",
    "\n",
    "Starting from this version, there's no need to match any numbering to the final report since it is already done. This version is set to v4. Because tis is just for correction, no profiling was done.\n",
    "\n",
    "#### 7.6.1 Model v4 Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def grad_vec2_nb3(X, y, q_W1, q_W2, q_W3, p_W4, p_W5, q_b1, q_b2, q_b3, p_b4, p_b5, q_h1, p_h2, q_mu, q_s2, z, eps):\n",
    "    \"\"\"\"\n",
    "    batch gradient calculation - vectorized version\n",
    "    not using lists for parameters to enable numba nopython\n",
    "    \n",
    "    inputs:\n",
    "        X: Data [M by dx]\n",
    "        y: Model results [M by L by dx]\n",
    "        q_W1 (dm by dx), q_W2 (dz by dm), q_W3 (dz by dm): Weights for encoder\n",
    "        p_W4 (dm by dz), p_W5 (dx by dm): Weights for decoder\n",
    "        q_b1, q_b2, q_b3: Bias for encoder\n",
    "        p_b4, p_b5: Bias for decoder\n",
    "        q_h1 (M by dm), p_h2 (M by L by dm): intermediate activation variables\n",
    "        eps (M by L by dz), z (M by L by dz), q_s2 (M by dz), q_mu (M by dz): for sampling latent variables from posterior\n",
    "    \"\"\"\n",
    "    \n",
    "    M, L, d = y.shape\n",
    "    \n",
    "    # initialize gradient variables\n",
    "    \n",
    "    # L: loss; R: regularization; J: total target\n",
    "    dL_dW1 = dJ_dW1 = dR_dW1 = np.zeros_like(q_W1)\n",
    "    dL_db1 = dJ_db1 = dR_db1 = np.zeros_like(q_b1)\n",
    "    dL_dW2 = dJ_dW2 = dR_dW2 = np.zeros_like(q_W2)\n",
    "    dL_db2 = dJ_db2 = dR_db2 = np.zeros_like(q_b2)\n",
    "    dL_dW3 = dJ_dW3 = dR_dW3 = np.zeros_like(q_W3)\n",
    "    dL_db3 = dJ_db3 = dR_db3 = np.zeros_like(q_b3)\n",
    "    dL_dW4 = dJ_dW4 = np.zeros_like(p_W4)\n",
    "    dL_db4 = dJ_db4 = np.zeros_like(p_b4)    \n",
    "    dL_dW5 = dJ_dW5 = np.zeros_like(p_W5)\n",
    "    dL_db5 = dJ_db5 = np.zeros_like(p_b5)\n",
    "\n",
    "    # back propagation for loss\n",
    "    for iL in range(L):\n",
    "        y_iL = y[:,iL,:] # M by dx\n",
    "        p_h2_iL = p_h2[:,iL,:] # M by dm\n",
    "        z_iL = z[:,iL,:] # M by dz\n",
    "        \n",
    "        L_d4 = y_iL - X # M by dx\n",
    "        dL_dW5 = dL_dW5 + L_d4.T @ p_h2_iL # dx by dm\n",
    "        dL_db5 = dL_db5 + np.sum(L_d4, axis = 0).reshape(-1,1) # dx by 1\n",
    "        \n",
    "        L_d3 = L_d4 @ p_W5 * tanh_gradient_nb(p_h2_iL) # M by dm\n",
    "        dL_dW4 = dL_dW4 + L_d3.T @ z_iL # dm by dz\n",
    "        dL_db4 = dL_db4 + np.sum(L_d3, axis = 0).reshape(-1,1) # dm by 1\n",
    "        \n",
    "        L_d22 = L_d3 @ p_W4 * eps[:,iL,] * np.sqrt(q_s2) / 2  # M by dz\n",
    "        dL_dW3 = dL_dW3 + L_d22.T @ q_h1 # dz by dm\n",
    "        dL_db3 = dL_db3 + np.sum(L_d22, axis = 0).reshape(-1,1) # dz by 1\n",
    "        \n",
    "        L_d21 = L_d3 @ p_W4 # M by dz\n",
    "        dL_dW2 = dL_dW2 + L_d21.T @ q_h1 # dz by dm\n",
    "        dL_db2 = dL_db2 + np.sum(L_d21, axis = 0).reshape(-1,1) # dz by 1\n",
    "\n",
    "        L_d1 = (L_d21 @ q_W2 + L_d22 @ q_W3) * tanh_gradient_nb(q_h1) # M by dm\n",
    "        dL_dW1 = dL_dW1 + L_d1.T @ X # dm by dx\n",
    "        dL_db1 = dL_db1 + np.sum(L_d1, axis = 0).reshape(-1,1) # dm by 1\n",
    "\n",
    "    # back propagation for regularization\n",
    "    R_d22 = (q_s2 - 1)/2 # M by dz\n",
    "    dR_dW3 = dR_dW3 + R_d22.T @ q_h1 # dz by dm\n",
    "    dR_db3 = dR_db3 + np.sum(R_d22, axis = 0).reshape(-1,1) # dz by 1\n",
    "    \n",
    "    R_d21 = q_mu # M by dz\n",
    "    dR_dW2 = dR_dW2 + R_d21.T @ q_h1 # dz by dm\n",
    "    dR_db2 = dR_db2 + np.sum(R_d21, axis = 0).reshape(-1,1) # dm by 1\n",
    "\n",
    "    R_d1 = (R_d22 @ q_W3 + R_d21 @ q_W2) * tanh_gradient_nb(q_h1) # M by dm\n",
    "    dR_dW1 = dR_dW1 + R_d1.T @ X # dm by dx\n",
    "    dR_db1 = dR_db1 + np.sum(R_d1, axis = 0).reshape(-1,1) # dm by 1\n",
    "    \n",
    "    dJ_dW1 = dL_dW1 / L / M + dR_dW1 / M\n",
    "    dJ_db1 = dL_db1 / L / M + dR_db1 / M\n",
    "    dJ_dW2 = dL_dW2 / L / M + dR_dW2 / M\n",
    "    dJ_db2 = dL_db2 / L / M + dR_db2 / M    \n",
    "    dJ_dW3 = dL_dW3 / L / M + dR_dW3 / M\n",
    "    dJ_db3 = dL_db3 / L / M + dR_db3 / M\n",
    "    dJ_dW4 = dL_dW4 / L / M\n",
    "    dJ_db4 = dL_db4 / L / M \n",
    "    dJ_dW5 = dL_dW5 / L / M\n",
    "    dJ_db5 = dL_db5 / L / M\n",
    "    \n",
    "    return dJ_dW1, dJ_dW2, dJ_dW3, dJ_dW4, dJ_dW5, dJ_db1, dJ_db2, dJ_db3, dJ_db4, dJ_db5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(cache=True)\n",
    "def train_AEVB_v4(trainX, trainy, nBatch, M = 100, L = 1, std_const = 255, dm = 500, dz = 3, alpha = 0.005, beta1 = 0.9, beta2 = 0.999, eps_stable = 1e-8, W = \"\", b = \"\", nP = 0):\n",
    "    \"\"\"\n",
    "    Internal notes: with model correction for latent variable sampling.\n",
    "    \n",
    "    AEVB model as described in the paper\n",
    "    Diederik P Kingma, Max Welling\n",
    "    Auto-Encoding Variational Bayes (2013).\n",
    "    \n",
    "    Training using ADAM algorithm as described in the paper\n",
    "    Diederik P Kingma, Jimmy Ba\n",
    "    Adam: A Method for Stochastic Optimization (2014).\n",
    "    \n",
    "    Input parameters\n",
    "    ----------\n",
    "    trainX: array_like\n",
    "            Training dataset inputs.\n",
    "            Dimension: number of sample by dx\n",
    "    trainy: array_like\n",
    "            Training dataset labels. \n",
    "            This variable is not currently used in the function. For further developments.\n",
    "    nBatch: integer\n",
    "            Number of mini-batch to train.\n",
    "    M: integer, optional\n",
    "            Size of mini-batch.\n",
    "            Default at 100 as recommended in the paper.\n",
    "    L: integer, optional\n",
    "            Number of latent variable to sample.\n",
    "            Default at 1 as recommended in the paper.\n",
    "    std_const: scalar, optional\n",
    "            Normlizing constant for data.\n",
    "            Currently default at 255 which is usually used for black and white image data.\n",
    "    dm: integer, optional\n",
    "            Dimension for middle layer of the encoder and decoder.\n",
    "            Default at 500 which used for MNIST dataset in the paper.\n",
    "    dz: integer, optional\n",
    "            Dimension for latent variables. \n",
    "            Currently default at 3\n",
    "    alpha: float, optional\n",
    "            Learning rate.\n",
    "            Default at 0.005.\n",
    "    beta1: float, optional\n",
    "            Parameter for ADAM.\n",
    "            Default at 0.9.\n",
    "    beta2: float, optional\n",
    "            Parameter for ADAM.\n",
    "            Default at 0.999.\n",
    "    eps_stable: float, optional\n",
    "            Parameter for ADAM.\n",
    "            Default at 1e-08.\n",
    "    W: list, optional\n",
    "            List of model weights parameters, same format as function output variable W.\n",
    "            In case user wants to start training from existing parameters.\n",
    "    b: list, optional\n",
    "            List of model bias parameters, same format as function output variable b.\n",
    "            In case user wants to start training from existing parameters.\n",
    "    nP: integer, optional\n",
    "            If specified with non-zero number, function will print out \n",
    "            status message after completing every nP batches.\n",
    "    \n",
    "    Returns:\n",
    "    ----------\n",
    "    W: list\n",
    "            List of model weights parameters in the order of: q_W1, q_W2, q_W3, p_W4, p_W5.\n",
    "            q_W1, q_W2, q_W3: weights for Gaussian MLP encoder as specified in paper Appendix C.\n",
    "            p_W4, p_W5: weights for Bernoulli MLP decoder as specified in paper Appendix C\n",
    "    b: list\n",
    "            List of model bias parameters in the order of q_b1, q_b2, q_b3, p_b4, p_b5.\n",
    "            q_b1, q_b2, q_b3: bias for Gaussian MLP encoder as specified in paper Appendix C.\n",
    "            p_b4, p_b5: weights for Bernoulli MLP decoder as specified in paper Appendix C.\n",
    "    loss: array-like\n",
    "            Array which stores total loss for each mini-batch.\n",
    "    \"\"\"\n",
    "    \n",
    "    dx = trainX.shape[1]\n",
    "    Spec = [nBatch, M, L, std_const, dx, dm, dz, alpha, nP]\n",
    "    \n",
    "    # initiate parameters for ADAM\n",
    "    # need to use separate lines of codes otherwise they share the same reference\n",
    "    v_dW, v_db = init_random_nb1(dx, dm, dz, option = \"zeros\")\n",
    "    s_dW, s_db = init_random_nb1(dx, dm, dz, option = \"zeros\")\n",
    "    vc_dW, vc_db = init_random_nb1(dx, dm, dz, option = \"zeros\")\n",
    "    sc_dW, sc_db = init_random_nb1(dx, dm, dz, option = \"zeros\")\n",
    "    num_para = len(v_dW)\n",
    "    \n",
    "    # weights and bias initialization\n",
    "    if len(W) == len(b) == 0:\n",
    "        W, b = init_random_nb1(dx, dm, dz)\n",
    "\n",
    "    # loss\n",
    "    loss = np.zeros(nBatch)\n",
    "    \n",
    "    for iB in range(nBatch):\n",
    "        # sample a random batch\n",
    "        batchX, batchy = get_Batch_nb(M, trainX, trainy)\n",
    "        X = batchX.reshape(M, dx) / std_const\n",
    "\n",
    "        # sample random noise for latent variable, assuming each batch uses the same random noise for now\n",
    "        eps = np.random.randn(M, L, dz)\n",
    "\n",
    "        y, q_h1, p_h2, q_mu, q_s2, z, loss[iB] = batch_forward_vec_nb2(Spec, X, W, b, eps)\n",
    "            \n",
    "        q_W1, q_W2, q_W3, p_W4, p_W5 = W\n",
    "        q_b1, q_b2, q_b3, p_b4, p_b5 = b\n",
    "        \n",
    "        dJ_dW1, dJ_dW2, dJ_dW3, dJ_dW4, dJ_dW5, dJ_db1, dJ_db2, dJ_db3, dJ_db4, dJ_db5 =\\\n",
    "        grad_vec2_nb3(X, y, q_W1, q_W2, q_W3, p_W4, p_W5, q_b1, q_b2, q_b3, p_b4, p_b5, q_h1, p_h2, q_mu, q_s2, z, eps)\n",
    "        \n",
    "        dW = [dJ_dW1, dJ_dW2, dJ_dW3, dJ_dW4, dJ_dW5]\n",
    "        db = [dJ_db1, dJ_db2, dJ_db3, dJ_db4, dJ_db5]\n",
    "        \n",
    "        # ADAM\n",
    "        for i in range(num_para):\n",
    "            v_dW[i] = beta1*v_dW[i] + (1-beta1)*dW[i]\n",
    "            v_db[i] = beta1*v_db[i] + (1-beta1)*db[i]\n",
    "            s_dW[i] = beta2*s_dW[i] + (1-beta2)*np.power(dW[i],2)\n",
    "            s_db[i] = beta2*s_db[i] + (1-beta2)*np.power(db[i],2)\n",
    "        \n",
    "            vc_dW[i] = v_dW[i]/(1-beta1**(iB+1))\n",
    "            vc_db[i] = v_db[i]/(1-beta1**(iB+1))\n",
    "            sc_dW[i] = s_dW[i]/(1-beta2**(iB+1))\n",
    "            sc_db[i] = s_db[i]/(1-beta2**(iB+1))\n",
    "        \n",
    "            dW[i] = vc_dW[i] / (np.sqrt(sc_dW[i]) + eps_stable)\n",
    "            db[i] = vc_db[i] / (np.sqrt(sc_db[i]) + eps_stable)\n",
    "        \n",
    "        W, b = para_update_nb(W, b, dW, db, alpha)\n",
    "        \n",
    "        if (nP != 0) and (iB+1) % nP == 0:\n",
    "            print(\"Batch \" + str(iB+1) + \" completed.\")\n",
    "\n",
    "    return W, b, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.7 pybind11 + Eigen\n",
    "\n",
    "Some notes for working with pybind11 + Eigen.\n",
    "\n",
    "1. I guess the reason why it's called \"pybind11\" is because it works with c++11. So any features that are only on c++14 or c++17 does not work.\n",
    "2. Suppose I write a cpp file and try to use cppimport to read it in and bind it to a variable called eigen_t. The first thing that needs to be done is to get the cpp file pass the compiler. Otherwise will keep getting \"gcc\" errors when trying to bind the eigen library to python variable. It's very tricky to know exactly where's the problems. Here I list down a few common ones to check first:\n",
    "    - forgetting \";\" at the end of sentence\n",
    "    - forget to declare variable\n",
    "    - function input/ output doesn't match\n",
    "3. If checked all obvious reasons and still cannot figure out why, the most efficient way (compared to random guess and wait for miracle to show by themselves), is to write cpp file to check. In that way, the compiler error would be popped up with more details. Refer to section 7.7.1 for the basic set up to do testing. If anything unclear or cannot run, google, or refer back to 663 notebook S12_CPP.\n",
    "4. Before the cpp file pass the compiler, basically the binding to the pythong variable won't work yet. And once it passes the compiler, it'll be assigned to the python variable, for example call it \"eigen_t\" here. After this, I can still make changes to the cpp file by overwriting it, but when I read it back, the new information doesn't seem to be able to automatically overwrite \"eigen_t\". For example, if I make change to one function to correct it, it won't flow through, or if I add a new function in the cpp file, it won't show up in python by simply re-reading the file. Here I need to restart the kernel for it to work. [perhaps should do some research to see whether there are ways to force it to happen].\n",
    "\n",
    "However, this turns out to be slower than our last version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.7.1 C++ Codes Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codes in this section is to check compiler errors for the c++ codes. I've made everything into text format for now because ... not sure why, if I have jupyter workbook run through these codes, then the \"grad_vec_nb3\" function will die (kernel die) while compiling through numba..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%file test_eigen.cpp\n",
    "#include <algorithm> // std::random_shuffle\n",
    "#include <random>\n",
    "#include <functional>\n",
    "#include <Eigen/Dense>\n",
    "#include <cstdlib> // std::rand, std::srand\n",
    "#include <iostream>\n",
    "#include <fstream>\n",
    "\n",
    "using namespace Eigen;\n",
    "using std::default_random_engine;\n",
    "using std::normal_distribution;\n",
    "using std::random_shuffle;\n",
    "using std::rand;\n",
    "using std::srand;\n",
    "using std::tuple;\n",
    "using std::make_tuple;\n",
    "using std::string;\n",
    "using std::tie;\n",
    "        \n",
    "using std::cout;\n",
    "using std::endl;\n",
    "using std::ofstream;\n",
    "\n",
    "\n",
    "// testing print in C++\n",
    "int test_print(int M){\n",
    "    for (int i=0; i<M; i++) {\n",
    "        cout << i << \"\\n\";\n",
    "    }\n",
    "    \n",
    "    return 5;\n",
    "}\n",
    "\n",
    "                    \n",
    "int main() \n",
    "{\n",
    "    srand(time(NULL));\n",
    "    string s = \"zeros\";\n",
    "    MatrixXd q_W1, p_W5, X;\n",
    "    int dm = 2;\n",
    "    int dx = 5;\n",
    "    int dz = 1;\n",
    "    int M = 3;\n",
    "\n",
    "    q_W1 = MatrixXd::Random(dm, dx);\n",
    "   \n",
    "    VectorXd q_b1 = VectorXd::Zero(dm);\n",
    "    \n",
    "    X = MatrixXd::Constant(M, dx, 1);\n",
    "    \n",
    "    int nP = 2;\n",
    "    \n",
    "    if ((nP !=0) && (2 % nP == 0)){\n",
    "        nP = 1;\n",
    "    }\n",
    "    \n",
    "    MatrixXd temp1, temp2;\n",
    "    cout << \"X\\n\" << X << \"\\n\";\n",
    "    cout << \"nP\" << nP << \"\\n\";\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%bash\n",
    "\n",
    "g++ -o test_eigen.exe test_eigen.cpp -std=c++11 -I./eigen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%bash\n",
    "\n",
    "./test_eigen.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section is for testing with pybind11 + Eigen. Not really used in the final eigen library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cppimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting eigen_testing.cpp\n"
     ]
    }
   ],
   "source": [
    "%%file eigen_testing.cpp\n",
    "<%\n",
    "cfg['compiler_args'] = ['-std=c++11']\n",
    "cfg['include_dirs'] = ['eigen']\n",
    "setup_pybind11(cfg)\n",
    "%>\n",
    "\n",
    "// v1.0\n",
    "#include <pybind11/pybind11.h>\n",
    "#include <pybind11/eigen.h>\n",
    "\n",
    "#include <Eigen/Dense>\n",
    "\n",
    "namespace py = pybind11;\n",
    "\n",
    "// matrix multiplication\n",
    "Eigen::MatrixXd mmult(Eigen::MatrixXd m1, Eigen::MatrixXd m2) {\n",
    "    return m1 * m2;\n",
    "}\n",
    "    \n",
    "// element wise multiplication\n",
    "Eigen::MatrixXd emult(Eigen::MatrixXd m1, Eigen::MatrixXd m2) {\n",
    "    return m1.array() * m2.array();\n",
    "}\n",
    "    \n",
    "// matrix addition    \n",
    "Eigen::MatrixXd add(Eigen::MatrixXd m1, Eigen::MatrixXd m2) {\n",
    "    return m1 + m2;\n",
    "}   \n",
    "\n",
    "// matrix substraction \n",
    "Eigen::MatrixXd substract(Eigen::MatrixXd m1, Eigen::MatrixXd m2) {\n",
    "    return m1 - m2;\n",
    "} \n",
    "\n",
    "// initialize matrix with all zero like input matrix\n",
    "Eigen::MatrixXd zeros_like(Eigen::MatrixXd m1) {\n",
    "    Eigen::MatrixXd m2 = Eigen::MatrixXd::Zero(m1.rows(), m1.cols());\n",
    "    return m2;\n",
    "} \n",
    "\n",
    "PYBIND11_MODULE(eigen_testing, m) {\n",
    "    m.doc() = \"auto-compiled c++ extension\";\n",
    "    m.def(\"mmult\", &mmult);\n",
    "    m.def(\"emult\", &emult);\n",
    "    m.def(\"add\", &add);\n",
    "    m.def(\"substract\", &substract);\n",
    "    m.def(\"zeros_like\", &zeros_like);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  1]\n",
      " [ 2  1  0]\n",
      " [-1  1  2]]\n",
      "[[4. 4. 4.]\n",
      " [3. 3. 3.]\n",
      " [2. 2. 2.]]\n",
      "[[ 1.  2.  1.]\n",
      " [ 2.  1.  0.]\n",
      " [-1.  1.  2.]]\n",
      "[[2. 3. 2.]\n",
      " [3. 2. 1.]\n",
      " [0. 2. 3.]]\n",
      "[[ 0.  1.  0.]\n",
      " [ 1.  0. -1.]\n",
      " [-2.  0.  1.]]\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "eigen_testing = cppimport.imp(\"eigen_testing\")\n",
    "\n",
    "A = np.array([[1,2,1],\n",
    "              [2,1,0],\n",
    "              [-1,1,2]])\n",
    "\n",
    "B = np.ones((3,3))\n",
    "\n",
    "print(A)\n",
    "print(eigen_testing.mmult(A,B))\n",
    "print(eigen_testing.emult(A,B))\n",
    "print(eigen_testing.add(A,B))\n",
    "print(eigen_testing.substract(A,B))\n",
    "print(eigen_testing.zeros_like(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.7.2 Model v5 Codes\n",
    "\n",
    "##### Pybind + Eigen library for Model v5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting eigen_lib.cpp\n"
     ]
    }
   ],
   "source": [
    "%%file eigen_lib.cpp\n",
    "<%\n",
    "cfg['compiler_args'] = ['-std=c++11']\n",
    "cfg['include_dirs'] = ['eigen']\n",
    "setup_pybind11(cfg)\n",
    "%>\n",
    "\n",
    "#include <pybind11/pybind11.h>\n",
    "#include <pybind11/eigen.h>\n",
    "#include <algorithm> // std::random_shuffle\n",
    "#include <random>\n",
    "#include <functional>\n",
    "#include <Eigen/Dense>\n",
    "#include <cstdlib> // std::rand, std::srand\n",
    "\n",
    "namespace py = pybind11;\n",
    "using namespace Eigen;\n",
    "using std::default_random_engine;\n",
    "using std::normal_distribution;\n",
    "using std::random_shuffle;\n",
    "using std::rand;\n",
    "using std::srand;\n",
    "using std::tuple;\n",
    "using std::make_tuple;\n",
    "using std::string;\n",
    "using std::tie;\n",
    "\n",
    "// start random number engine with fixed seed\n",
    "default_random_engine re{421};\n",
    "normal_distribution<double> norm(0,1); // mean and standard deviation\n",
    "auto rnorm = bind(norm, re);\n",
    "\n",
    "// sigmoid function\n",
    "MatrixXd sigmoid(Ref<const MatrixXd> m1) {\n",
    "    return 1/(1+ (-m1).array().exp());\n",
    "}   \n",
    "    \n",
    "// gradient of sigmoid function\n",
    "MatrixXd sigmoid_gradient(Ref<const MatrixXd> m1) {\n",
    "    return m1.array() * (1 - m1.array());\n",
    "}\n",
    "\n",
    "// gradient of tanh function\n",
    "MatrixXd tanh_gradient(Ref<const MatrixXd> m1) {\n",
    "    return 1- m1.array().pow(2);\n",
    "}\n",
    "\n",
    "// tanh function\n",
    "MatrixXd mtanh(Ref<const MatrixXd> m1) {\n",
    "    return m1.array().tanh();\n",
    "}\n",
    "\n",
    "int myrandom (int i){\n",
    "    return rand()%i;\n",
    "}\n",
    "\n",
    "// get random mini-batch\n",
    "MatrixXd get_batch(int M, Ref<const MatrixXd> trainX){\n",
    "    int N = trainX.rows();\n",
    "    int dx = trainX.cols();\n",
    "    MatrixXd batchX = MatrixXd::Zero(M, dx);\n",
    "    \n",
    "    VectorXi indices = VectorXi::LinSpaced(N, 1, N);\n",
    "    random_shuffle(indices.begin(), indices.end(), myrandom);\n",
    "    \n",
    "    for (int i=0; i<M; i++) {\n",
    "        batchX.row(i) = trainX.row(indices(i));\n",
    "    }\n",
    "    \n",
    "    return batchX;\n",
    "}\n",
    "\n",
    "// initialize variables\n",
    "tuple<MatrixXd, MatrixXd, MatrixXd, MatrixXd, MatrixXd, VectorXd, VectorXd, VectorXd, VectorXd, VectorXd>\n",
    "init_para(int dx, int dm, int dz, string option){\n",
    "    \n",
    "    MatrixXd q_W1, q_W2, q_W3, p_W4, p_W5;\n",
    "    VectorXd q_b1, q_b2, q_b3, p_b4, p_b5;\n",
    "    double bound;\n",
    "    \n",
    "    // weights initialization\n",
    "    if (option == \"zeros\"){ // initialize all zero for ADAM\n",
    "        q_W1 = MatrixXd::Zero(dm, dx);\n",
    "        p_W5 = MatrixXd::Zero(dx, dm);\n",
    "        q_W2 = MatrixXd::Zero(dz, dm);\n",
    "        q_W3 = MatrixXd::Zero(dz, dm);\n",
    "        p_W4 = MatrixXd::Zero(dm, dz);\n",
    "    } else if (option == \"xavier\") { // xavier initialization\n",
    "        bound = sqrt(6)/ sqrt(dx + dm);\n",
    "        q_W1 = MatrixXd::Random(dm, dx) * bound;\n",
    "        p_W5 = MatrixXd::Random(dx, dm) * bound;\n",
    "        bound = sqrt(6)/ sqrt(dm + dz);\n",
    "        q_W2 = MatrixXd::Random(dz, dm) * bound;\n",
    "        q_W3 = MatrixXd::Random(dz, dm) * bound;\n",
    "        p_W4 = MatrixXd::Random(dm, dz) * bound;\n",
    "    }\n",
    "    \n",
    "    // bias initialization\n",
    "    q_b1 = VectorXd::Zero(dm);\n",
    "    p_b5 = VectorXd::Zero(dx);  \n",
    "    q_b2 = VectorXd::Zero(dz);\n",
    "    q_b3 = VectorXd::Zero(dz);\n",
    "    p_b4 = VectorXd::Zero(dm);\n",
    "   \n",
    "    return make_tuple(q_W1, q_W2, q_W3, p_W4, p_W5, q_b1, q_b2, q_b3, p_b4, p_b5);\n",
    "}\n",
    "\n",
    "// encoder forward\n",
    "tuple<MatrixXd, MatrixXd, MatrixXd, MatrixXd>\n",
    "encoder_forward(Ref<const MatrixXd> X, Ref<const MatrixXd> q_W1, Ref<const MatrixXd> q_W2, Ref<const MatrixXd> q_W3,\n",
    "               Ref<const VectorXd> q_b1, Ref<const VectorXd> q_b2, Ref<const VectorXd> q_b3){\n",
    "    \n",
    "    MatrixXd q_a1, q_h1, q_mu, q_a2, q_s2;\n",
    "    \n",
    "    q_a1 = (q_W1 * X.transpose()).colwise() + q_b1; // dm by M\n",
    "    q_h1 = mtanh(q_a1); // dm by M\n",
    "    q_mu = (q_W2 * q_h1).colwise() + q_b2; // dz by M\n",
    "    q_a2 = (q_W3 * q_h1).colwise() + q_b3; // dz by M\n",
    "    q_s2 = q_a2.array().exp(); // dz by M\n",
    "    \n",
    "    return make_tuple(q_h1.transpose(), q_a2.transpose(), q_mu.transpose(), q_s2.transpose());\n",
    "\n",
    "}\n",
    "\n",
    "// decoder forward\n",
    "tuple<MatrixXd, MatrixXd>\n",
    "decoder_forward(Ref<const MatrixXd> p_W4, Ref<const MatrixXd> p_W5, Ref<const VectorXd> p_b4, \n",
    "                Ref<const VectorXd> p_b5, Ref<const MatrixXd> z){\n",
    "    \n",
    "    MatrixXd p_a3, p_h2, p_a4, y;\n",
    "    \n",
    "    p_a3 = (z * p_W4.transpose()).rowwise() + p_b4.transpose(); // M by dm\n",
    "    p_h2 = mtanh(p_a3); // M by dm\n",
    "    p_a4 = (p_h2 * p_W5.transpose()).rowwise() + p_b5.transpose(); // M by dx\n",
    "    y = sigmoid(p_a4); // M by dx\n",
    "    \n",
    "    return make_tuple(y, p_h2);\n",
    "\n",
    "}\n",
    "\n",
    "// Gaussian encoder back-propagation\n",
    "tuple<MatrixXd, MatrixXd, MatrixXd, VectorXd, VectorXd, VectorXd>\n",
    "encoder_back(Ref<const MatrixXd> X, Ref<const MatrixXd> q_W2, Ref<const MatrixXd> q_W3,\n",
    "       Ref<const MatrixXd> q_s2, Ref<const MatrixXd> q_h1, Ref<const MatrixXd> q_mu, \n",
    "             Ref<const MatrixXd> d22, Ref<const MatrixXd> d21){\n",
    "\n",
    "    // d22, d21: M by dz\n",
    "    \n",
    "    MatrixXd d1;\n",
    "    MatrixXd dW1, dW2, dW3;\n",
    "    VectorXd db1, db2, db3;\n",
    "    \n",
    "    dW3 = d22.transpose() * q_h1; // dz by dm\n",
    "    db3 = d22.colwise().sum().transpose(); // dz by 1\n",
    "\n",
    "    dW2 = d21.transpose() * q_h1; // dz by dm\n",
    "    db2 = d21.colwise().sum().transpose(); // dm by 1\n",
    "    \n",
    "    d1 = (d22 * q_W3 + d21 * q_W2).array() * tanh_gradient(q_h1).array(); // M by dm\n",
    "    dW1 = d1.transpose() * X; // dm by dx\n",
    "    db1 = d1.colwise().sum().transpose(); // dm by 1\n",
    "    \n",
    "    return make_tuple(dW1, dW2, dW3, db1, db2, db3);\n",
    "\n",
    "}\n",
    "\n",
    "// Bernoulli decoder back-propagation\n",
    "tuple<MatrixXd, MatrixXd, MatrixXd, MatrixXd, MatrixXd, VectorXd, VectorXd, VectorXd, VectorXd, VectorXd>\n",
    "decoder_back(Ref<const MatrixXd> X, Ref<const MatrixXd> q_W2, Ref<const MatrixXd> q_W3, Ref<const MatrixXd> p_W4,\n",
    "        Ref<const MatrixXd> p_W5, Ref<const MatrixXd> q_s2, Ref<const MatrixXd> q_h1, Ref<const MatrixXd> q_mu, \n",
    "             Ref<const MatrixXd> p_h2, Ref<const MatrixXd> eps, Ref<const MatrixXd> z, Ref<const MatrixXd> d4){\n",
    "\n",
    "    // d4 (M by dx); p_h2 (M by dm); eps (M by dz); z (M by dz)\n",
    "    \n",
    "    MatrixXd d1, d21, d22, d3;\n",
    "    MatrixXd dW1, dW2, dW3, dW4, dW5;\n",
    "    VectorXd db1, db2, db3, db4, db5;\n",
    "    \n",
    "    dW5 = d4.transpose() * p_h2; // dx by dm\n",
    "    db5 = d4.colwise().sum().transpose(); // dx by 1\n",
    "    \n",
    "    d3 = (d4 * p_W5).array() * tanh_gradient(p_h2).array(); // M by dm\n",
    "    dW4 = d3.transpose() * z; // dm by dz\n",
    "    db4 = d3.colwise().sum().transpose(); // dm by 1\n",
    "    \n",
    "    d22 = (d3 * p_W4).array() * eps.array() * q_s2.array().sqrt() / 2; // M by dz\n",
    "    d21 = d3 * p_W4; // M by dz\n",
    "    \n",
    "    tie(dW1, dW2, dW3, db1, db2, db3) = encoder_back(X, q_W2, q_W3, q_s2, q_h1, q_mu, d22, d21);\n",
    "    \n",
    "    return make_tuple(dW1, dW2, dW3, dW4, dW5, db1, db2, db3, db4, db5);\n",
    "\n",
    "}\n",
    "\n",
    "// batch gradient\n",
    "tuple<MatrixXd, MatrixXd, MatrixXd, MatrixXd, MatrixXd, VectorXd, VectorXd, VectorXd, VectorXd, VectorXd, double>\n",
    "batch_gradient(Ref<const MatrixXd> X, int L, Ref<const MatrixXd> q_W1, Ref<const MatrixXd> q_W2, \n",
    "              Ref<const MatrixXd> q_W3, Ref<const MatrixXd> p_W4, Ref<const MatrixXd> p_W5, \n",
    "              Ref<const VectorXd> q_b1, Ref<const VectorXd> q_b2, Ref<const VectorXd> q_b3, \n",
    "              Ref<const VectorXd> p_b4, Ref<const VectorXd> p_b5){\n",
    "    \n",
    "    int M = X.rows();\n",
    "    int dx = X.cols();\n",
    "    int dm = p_W4.rows();\n",
    "    int dz = p_W4.cols();\n",
    "    \n",
    "    MatrixXd q_h1, q_a2, q_mu, q_s2, y, p_h2, z, eps; //\n",
    "    MatrixXd d22, d21, d4;\n",
    "    MatrixXd R_dW1, R_dW2, R_dW3, dW1, dW2, dW3, dW4, dW5, t_dW1, t_dW2, t_dW3, t_dW4, t_dW5;\n",
    "    VectorXd R_db1, R_db2, R_db3, db1, db2, db3, db4, db5, t_db1, t_db2, t_db3, t_db4, t_db5;\n",
    "    double loss;\n",
    "    \n",
    "    // initialize parameters\n",
    "    tie(dW1, dW2, dW3, dW4, dW5, db1, db2, db3, db4, db5) = init_para(dx, dm, dz, \"zeros\");\n",
    "    tie(t_dW1, t_dW2, t_dW3, t_dW4, t_dW5, t_db1, t_db2, t_db3, t_db4, t_db5) = \n",
    "    init_para(dx, dm, dz, \"zeros\"); // t for temp\n",
    "\n",
    "    // encoder forward\n",
    "    tie(q_h1, q_a2, q_mu, q_s2) = encoder_forward(X, q_W1, q_W2, q_W3, q_b1, q_b2, q_b3);\n",
    "    \n",
    "    // KL divergence/ regularization\n",
    "    loss = (q_mu.array().pow(2) + q_s2.array() - q_a2.array() - 1).sum()/ 2/ M;\n",
    "    \n",
    "    // encoder back for KL divergence/ regularization\n",
    "    d22 = (q_s2.array() - 1)/ 2; // M by dz\n",
    "    d21 = q_mu; // M by dz\n",
    "    tie(R_dW1, R_dW2, R_dW3, R_db1, R_db2, R_db3) = encoder_back(X, q_W2, q_W3, q_s2, q_h1, q_mu, d22, d21);\n",
    "\n",
    "    for (int i=0; i<L; i++) {\n",
    "        // random normal noise M by dz\n",
    "        eps = MatrixXd::Zero(M, dz).unaryExpr([](double x) { return rnorm(); });\n",
    "        \n",
    "        // sample z, M by dz\n",
    "        z = q_mu.array() + q_s2.array().sqrt() * eps.array();\n",
    "        \n",
    "        // decoder forward\n",
    "        tie(y, p_h2) = decoder_forward(p_W4, p_W5, p_b4, p_b5, z);\n",
    "        \n",
    "        // reconstruction loss for each sample of latent variable\n",
    "        loss = loss - (X.array() * y.array().log() + (1- X.array()) * (1 - y.array()).log()).sum() / L / M;\n",
    "\n",
    "        // decoder back for reconstruction loss\n",
    "        d4 = y - X; // M by dx\n",
    "        tie(t_dW1, t_dW2, t_dW3, t_dW4, t_dW5, t_db1, t_db2, t_db3, t_db4, t_db5) = \n",
    "        decoder_back(X, q_W2, q_W3, p_W4, p_W5, q_s2, q_h1, q_mu, p_h2, eps, z, d4);\n",
    "        \n",
    "        dW1 = dW1 + t_dW1;\n",
    "        dW2 = dW2 + t_dW2;\n",
    "        dW3 = dW3 + t_dW3;\n",
    "        dW4 = dW4 + t_dW4;\n",
    "        dW5 = dW5 + t_dW5;\n",
    "        db1 = db1 + t_db1;\n",
    "        db2 = db2 + t_db2;\n",
    "        db3 = db3 + t_db3;\n",
    "        db4 = db4 + t_db4;\n",
    "        db5 = db5 + t_db5;\n",
    "    }\n",
    "    \n",
    "    dW1 = (dW1 / L + R_dW1) / M;\n",
    "    dW2 = (dW2 / L + R_dW2) / M;\n",
    "    dW3 = (dW3 / L + R_dW3) / M;\n",
    "    dW4 = dW4 / M;\n",
    "    dW5 = dW5 / M;\n",
    "    db1 = (db1 / L + R_db1) / M;\n",
    "    db2 = (db2 / L + R_db2) / M;\n",
    "    db3 = (db3 / L + R_db3) / M;\n",
    "    db4 = db4 / M;\n",
    "    db5 = db5 / M;\n",
    "\n",
    "    return make_tuple(dW1, dW2, dW3, dW4, dW5, db1, db2, db3, db4, db5, loss);\n",
    "}\n",
    "\n",
    "\n",
    "// ADAM\n",
    "tuple<MatrixXd, MatrixXd, MatrixXd, MatrixXd, MatrixXd, VectorXd, VectorXd, VectorXd, VectorXd, VectorXd, VectorXd>\n",
    "train_ADAM(Ref<const MatrixXd> trainX, MatrixXd q_W1, MatrixXd q_W2, MatrixXd q_W3, MatrixXd p_W4, MatrixXd p_W5,\n",
    "           VectorXd q_b1, VectorXd q_b2, VectorXd q_b3, VectorXd p_b4, VectorXd p_b5, \n",
    "           int nBatch, int M, int L, int std_const, int dm, int dz, \n",
    "           double alpha, double beta1, double beta2, double eps_stable, int nP){\n",
    "    \n",
    "    VectorXd loss = VectorXd::Zero(nBatch);\n",
    "    MatrixXd X;\n",
    "    MatrixXd dW1, dW2, dW3, dW4, dW5;\n",
    "    VectorXd db1, db2, db3, db4, db5;\n",
    "    double div1, div2;\n",
    "    \n",
    "    // parameters initialization for ADAM\n",
    "    MatrixXd v_dW1, v_dW2, v_dW3, v_dW4, v_dW5, s_dW1, s_dW2, s_dW3, s_dW4, s_dW5;\n",
    "    VectorXd v_db1, v_db2, v_db3, v_db4, v_db5, s_db1, s_db2, s_db3, s_db4, s_db5;\n",
    "\n",
    "    int dx = trainX.cols();\n",
    "    \n",
    "    tie(v_dW1, v_dW2, v_dW3, v_dW4, v_dW5, v_db1, v_db2, v_db3, v_db4, v_db5) = init_para(dx, dm, dz, \"zeros\"); \n",
    "    tie(s_dW1, s_dW2, s_dW3, s_dW4, s_dW5, s_db1, s_db2, s_db3, s_db4, s_db5) = init_para(dx, dm, dz, \"zeros\"); \n",
    "    \n",
    "    for (int i=0; i<nBatch; i++) {\n",
    "        \n",
    "        X = get_batch(M, trainX) / std_const;\n",
    "        div1 = 1 - pow(beta1, i+1);\n",
    "        div2 = 1 - pow(beta2, i+1);\n",
    "        \n",
    "        tie(dW1, dW2, dW3, dW4, dW5, db1, db2, db3, db4, db5, loss[i]) = \n",
    "        batch_gradient(X, L, q_W1, q_W2, q_W3, p_W4, p_W5, q_b1, q_b2, q_b3, p_b4, p_b5);\n",
    "        \n",
    "        v_dW1 = beta1 * v_dW1 + (1-beta1) * dW1;\n",
    "        v_dW2 = beta1 * v_dW2 + (1-beta1) * dW2;\n",
    "        v_dW3 = beta1 * v_dW3 + (1-beta1) * dW3;\n",
    "        v_dW4 = beta1 * v_dW4 + (1-beta1) * dW4;\n",
    "        v_dW5 = beta1 * v_dW5 + (1-beta1) * dW5;\n",
    "        v_db1 = beta1 * v_db1 + (1-beta1) * db1;   \n",
    "        v_db2 = beta1 * v_db2 + (1-beta1) * db2; \n",
    "        v_db3 = beta1 * v_db3 + (1-beta1) * db3; \n",
    "        v_db4 = beta1 * v_db4 + (1-beta1) * db4; \n",
    "        v_db5 = beta1 * v_db5 + (1-beta1) * db5; \n",
    "\n",
    "        s_dW1 = beta2 * s_dW1.array() + (1-beta2) * dW1.array().pow(2);\n",
    "        s_dW2 = beta2 * s_dW2.array() + (1-beta2) * dW2.array().pow(2);\n",
    "        s_dW3 = beta2 * s_dW3.array() + (1-beta2) * dW3.array().pow(2);\n",
    "        s_dW4 = beta2 * s_dW4.array() + (1-beta2) * dW4.array().pow(2);\n",
    "        s_dW5 = beta2 * s_dW5.array() + (1-beta2) * dW5.array().pow(2);\n",
    "        s_db1 = beta2 * s_db1.array() + (1-beta2) * db1.array().pow(2);\n",
    "        s_db2 = beta2 * s_db2.array() + (1-beta2) * db2.array().pow(2);\n",
    "        s_db3 = beta2 * s_db3.array() + (1-beta2) * db3.array().pow(2);\n",
    "        s_db4 = beta2 * s_db4.array() + (1-beta2) * db4.array().pow(2);\n",
    "        s_db5 = beta2 * s_db5.array() + (1-beta2) * db5.array().pow(2);\n",
    "        \n",
    "        dW1 = v_dW1.array() / div1 / ((s_dW1 / div2).array().sqrt() + eps_stable);\n",
    "        dW2 = v_dW2.array() / div1 / ((s_dW2 / div2).array().sqrt() + eps_stable);\n",
    "        dW3 = v_dW3.array() / div1 / ((s_dW3 / div2).array().sqrt() + eps_stable);\n",
    "        dW4 = v_dW4.array() / div1 / ((s_dW4 / div2).array().sqrt() + eps_stable);\n",
    "        dW5 = v_dW5.array() / div1 / ((s_dW5 / div2).array().sqrt() + eps_stable);\n",
    "        db1 = v_db1.array() / div1 / ((s_db1 / div2).array().sqrt() + eps_stable);\n",
    "        db2 = v_db2.array() / div1 / ((s_db2 / div2).array().sqrt() + eps_stable);\n",
    "        db3 = v_db3.array() / div1 / ((s_db3 / div2).array().sqrt() + eps_stable);\n",
    "        db4 = v_db4.array() / div1 / ((s_db4 / div2).array().sqrt() + eps_stable);\n",
    "        db5 = v_db5.array() / div1 / ((s_db5 / div2).array().sqrt() + eps_stable);\n",
    "    \n",
    "        q_W1 = q_W1 - alpha * dW1;\n",
    "        q_W2 = q_W2 - alpha * dW2;\n",
    "        q_W3 = q_W3 - alpha * dW3;\n",
    "        p_W4 = p_W4 - alpha * dW4;\n",
    "        p_W5 = p_W5 - alpha * dW5;\n",
    "        q_b1 = q_b1 - alpha * db1;\n",
    "        q_b2 = q_b2 - alpha * db2;\n",
    "        q_b3 = q_b3 - alpha * db3;\n",
    "        p_b4 = p_b4 - alpha * db4;\n",
    "        p_b5 = p_b5 - alpha * db5; \n",
    "        \n",
    "        if ((nP !=0) && ((i+1) % nP == 0)){\n",
    "            py::print(\"Batch\", (i+1), \"completed.\\n\");\n",
    "        }   \n",
    "    }    \n",
    "    \n",
    "    return make_tuple(q_W1, q_W2, q_W3, p_W4, p_W5, q_b1, q_b2, q_b3, p_b4, p_b5, loss);\n",
    "}\n",
    "\n",
    "PYBIND11_MODULE(eigen_lib, m) {\n",
    "    m.doc() = \"auto-compiled c++ extension\";\n",
    "    m.def(\"sigmoid\", &sigmoid);\n",
    "    m.def(\"sigmoid_gradient\", &sigmoid_gradient);\n",
    "    m.def(\"tanh_gradient\", &tanh_gradient);\n",
    "    m.def(\"tanh\", &mtanh);\n",
    "    m.def(\"get_batch\", &get_batch);\n",
    "    m.def(\"init_para\", &init_para);\n",
    "    m.def(\"encoder_forward\", &encoder_forward);\n",
    "    m.def(\"decoder_forward\", &decoder_forward);\n",
    "    m.def(\"encoder_back\", &encoder_back);\n",
    "    m.def(\"decoder_back\", &decoder_back);\n",
    "    m.def(\"batch_gradient\", &batch_gradient);\n",
    "    m.def(\"train_ADAM\", &train_ADAM);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Python code for model v5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_AEVB_v5(trainX, nBatch, M = 100, L = 1, std_const = 255, dm = 500, dz = 3, alpha = 0.005, beta1 = 0.9, beta2 = 0.999, eps_stable = 1e-8, W = \"\", b = \"\", loss = \"\", nP = 0):\n",
    "    \"\"\"\n",
    "    AEVB model as described in the paper\n",
    "    Diederik P Kingma, Max Welling\n",
    "    Auto-Encoding Variational Bayes (2013).\n",
    "    \n",
    "    Training using ADAM algorithm as described in the paper\n",
    "    Diederik P Kingma, Jimmy Ba\n",
    "    Adam: A Method for Stochastic Optimization (2014).\n",
    "    \n",
    "    Input parameters\n",
    "    ----------\n",
    "    trainX: array-like\n",
    "            Training dataset inputs.\n",
    "            Dimension: number of sample (M) by dx\n",
    "    nBatch: integer\n",
    "            Number of mini-batch to train.\n",
    "    M: integer, optional\n",
    "            Size of mini-batch.\n",
    "            Default at 100 as recommended in the paper.\n",
    "    L: integer, optional\n",
    "            Number of latent variable to sample.\n",
    "            Default at 1 as recommended in the paper.\n",
    "    std_const: scalar, optional\n",
    "            Normlizing constant for data.\n",
    "            Currently default at 255 which is usually used for black and white image data.\n",
    "    dm: integer, optional\n",
    "            Dimension for middle layer of the encoder and decoder.\n",
    "            Default at 500 which used for MNIST dataset in the paper.\n",
    "    dz: integer, optional\n",
    "            Dimension for latent variables. \n",
    "            Currently default at 3\n",
    "    alpha: float, optional\n",
    "            Learning rate.\n",
    "            Default at 0.005.\n",
    "    beta1: float, optional\n",
    "            Parameter for ADAM.\n",
    "            Default at 0.9.\n",
    "    beta2: float, optional\n",
    "            Parameter for ADAM.\n",
    "            Default at 0.999.\n",
    "    eps_stable: float, optional\n",
    "            Parameter for ADAM.\n",
    "            Default at 1e-08.\n",
    "    W: list, optional\n",
    "            List of model weights parameters, same format as function output variable W.\n",
    "            In case user wants to start training from existing parameters.\n",
    "    b: list, optional\n",
    "            List of model bias parameters, same format as function output variable b.\n",
    "            In case user wants to start training from existing parameters.\n",
    "    loss: array-like, optional\n",
    "            Vector of total loss, same format as function output variable loss.\n",
    "            In case user wants to start training from existing parameters.\n",
    "    nP: integer, optional\n",
    "            If specified with non-zero number, function will print out \n",
    "            status message after completing every nP batches.\n",
    "    \n",
    "    Returns:\n",
    "    ----------\n",
    "    W: list\n",
    "            List of model weights parameters in the order of: q_W1, q_W2, q_W3, p_W4, p_W5.\n",
    "            q_W1, q_W2, q_W3: weights for Gaussian MLP encoder as specified in paper Appendix C.\n",
    "            p_W4, p_W5: weights for Bernoulli MLP decoder as specified in paper Appendix C\n",
    "    b: list\n",
    "            List of model bias parameters in the order of q_b1, q_b2, q_b3, p_b4, p_b5.\n",
    "            q_b1, q_b2, q_b3: bias for Gaussian MLP encoder as specified in paper Appendix C.\n",
    "            p_b4, p_b5: weights for Bernoulli MLP decoder as specified in paper Appendix C.\n",
    "    loss: array-like\n",
    "            Array which stores total loss for each mini-batch.\n",
    "    \"\"\"\n",
    "    \n",
    "    eigen_lib = cppimport.imp(\"eigen_lib\")\n",
    "    \n",
    "    dx = trainX.shape[1]\n",
    "    if len(W) == len(b) == 0:\n",
    "        (q_W1, q_W2, q_W3, p_W4, p_W5, q_b1, q_b2, q_b3, p_b4, p_b5) = eigen_lib.init_para(dx, dm, dz, \"xavier\")\n",
    "    else:\n",
    "        q_W1, q_W2, q_W3, p_W4, p_W5 = W\n",
    "        q_b1, q_b2, q_b3, p_b4, p_b5 = b\n",
    "\n",
    "    (q_W1, q_W2, q_W3, p_W4, p_W5, q_b1, q_b2, q_b3, p_b4, p_b5, loss_out) = eigen_lib.train_ADAM(trainX, \\\n",
    "        q_W1, q_W2, q_W3, p_W4, p_W5, q_b1, q_b2, q_b3, p_b4, p_b5, nBatch, M, L, std_const, dm, dz, \\\n",
    "        alpha, beta1, beta2, eps_stable, nP)\n",
    "    \n",
    "    if len(loss) == 0:\n",
    "        loss = loss_out;\n",
    "    else:\n",
    "        loss = np.concatenate((loss, loss_out))\n",
    "    \n",
    "    W = [q_W1, q_W2, q_W3, p_W4, p_W5]\n",
    "    b = [q_b1, q_b2, q_b3, p_b4, p_b5]\n",
    "    \n",
    "    return W, b, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.7.3 Testing\n",
    "\n",
    "This section is for Model v5 testing vs existing functions in python (i.e., model v4 and past models). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pybind11 + Eigen test functions\n",
    "\n",
    "This subsection are pybind11+Eigen functions used for testing only, but not included in the final eigen library file.\n",
    "\n",
    "1.The first is \"test_total_loss\" function. When L is set to 1, can use this function to compare the output between eigen library and existing python functions. If want to use this function, copy the function and add the \"m.def\" line of codes back."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// test total loss\n",
    "double test_total_loss(Ref<const MatrixXd> X, Ref<const MatrixXd> y, Ref<const MatrixXd> q_a2,\n",
    "                      Ref<const MatrixXd> q_mu, Ref<const MatrixXd> q_s2, int M, int L){\n",
    "    \n",
    "    double loss;\n",
    "    \n",
    "    loss = (q_mu.array().pow(2) + q_s2.array() - q_a2.array() - 1).sum()/ 2/ M;\n",
    "    loss = loss - (X.array() * y.array().log() + (1- X.array()) * (1 - y.array()).log()).sum() / L / M;\n",
    "    \n",
    "    return loss;\n",
    "}\n",
    "\n",
    "m.def(\"test_total_loss\", &test_total_loss);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.The following are changes that I needed to make to batch_gradient and train_ADAM in order to be able to use the same \"eps\" and \"z\" to test for gradient calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// batch gradient\n",
    "tuple<MatrixXd, MatrixXd, MatrixXd, MatrixXd, MatrixXd, VectorXd, VectorXd, VectorXd, VectorXd, VectorXd, double>\n",
    "batch_gradient(Ref<const MatrixXd> X, int L, Ref<const MatrixXd> q_W1, Ref<const MatrixXd> q_W2, \n",
    "              Ref<const MatrixXd> q_W3, Ref<const MatrixXd> p_W4, Ref<const MatrixXd> p_W5, \n",
    "              Ref<const VectorXd> q_b1, Ref<const VectorXd> q_b2, Ref<const VectorXd> q_b3, \n",
    "              Ref<const VectorXd> p_b4, Ref<const VectorXd> p_b5){\n",
    "    \n",
    "    int M = X.rows();\n",
    "    int dx = X.cols();\n",
    "    int dm = p_W4.rows();\n",
    "    int dz = p_W4.cols();\n",
    "    \n",
    "    MatrixXd q_h1, q_a2, q_mu, q_s2, y, p_h2; //, z, eps\n",
    "    MatrixXd d22, d21, d4;\n",
    "    MatrixXd R_dW1, R_dW2, R_dW3, dW1, dW2, dW3, dW4, dW5, t_dW1, t_dW2, t_dW3, t_dW4, t_dW5;\n",
    "    VectorXd R_db1, R_db2, R_db3, db1, db2, db3, db4, db5, t_db1, t_db2, t_db3, t_db4, t_db5;\n",
    "    double loss;\n",
    "    \n",
    "    // initialize parameters\n",
    "    tie(dW1, dW2, dW3, dW4, dW5, db1, db2, db3, db4, db5) = init_para(dx, dm, dz, \"zeros\");\n",
    "    tie(t_dW1, t_dW2, t_dW3, t_dW4, t_dW5, t_db1, t_db2, t_db3, t_db4, t_db5) = \n",
    "    init_para(dx, dm, dz, \"zeros\"); // t for temp\n",
    "\n",
    "    // encoder forward\n",
    "    tie(q_h1, q_a2, q_mu, q_s2) = encoder_forward(X, q_W1, q_W2, q_W3, q_b1, q_b2, q_b3);\n",
    "    \n",
    "    // KL divergence/ regularization\n",
    "    loss = (q_mu.array().pow(2) + q_s2.array() - q_a2.array() - 1).sum()/ 2/ M;\n",
    "    \n",
    "    // encoder back for KL divergence/ regularization\n",
    "    d22 = (q_s2.array() - 1)/ 2; // M by dz\n",
    "    d21 = q_mu; // M by dz\n",
    "    tie(R_dW1, R_dW2, R_dW3, R_db1, R_db2, R_db3) = encoder_back(X, q_W2, q_W3, q_s2, q_h1, q_mu, d22, d21);\n",
    "\n",
    "    for (int i=0; i<L; i++) {\n",
    "        // random normal noise M by dz\n",
    "        // eps = MatrixXd::Zero(M, dz).unaryExpr([](double x) { return rnorm(); });\n",
    "        \n",
    "        // sample z, M by dz\n",
    "        // z = q_mu.array() + q_s2.array().sqrt() * eps.array();\n",
    "        \n",
    "        // decoder forward\n",
    "        tie(y, p_h2) = decoder_forward(p_W4, p_W5, p_b4, p_b5, z);\n",
    "        \n",
    "        // reconstruction loss for each sample of latent variable\n",
    "        loss = loss - (X.array() * y.array().log() + (1- X.array()) * (1 - y.array()).log()).sum() / L / M;\n",
    "\n",
    "        // decoder back for reconstruction loss\n",
    "        d4 = y - X; // M by dx\n",
    "        tie(t_dW1, t_dW2, t_dW3, t_dW4, t_dW5, t_db1, t_db2, t_db3, t_db4, t_db5) = \n",
    "        decoder_back(X, q_W2, q_W3, p_W4, p_W5, q_s2, q_h1, q_mu, p_h2, eps, z, d4);\n",
    "        \n",
    "        dW1 = dW1 + t_dW1;\n",
    "        dW2 = dW2 + t_dW2;\n",
    "        dW3 = dW3 + t_dW3;\n",
    "        dW4 = dW4 + t_dW4;\n",
    "        dW5 = dW5 + t_dW5;\n",
    "        db1 = db1 + t_db1;\n",
    "        db2 = db2 + t_db2;\n",
    "        db3 = db3 + t_db3;\n",
    "        db4 = db4 + t_db4;\n",
    "        db5 = db5 + t_db5;\n",
    "    }\n",
    "    \n",
    "    dW1 = (dW1 / L + R_dW1) / M;\n",
    "    dW2 = (dW2 / L + R_dW2) / M;\n",
    "    dW3 = (dW3 / L + R_dW3) / M;\n",
    "    dW4 = dW4 / M;\n",
    "    dW5 = dW5 / M;\n",
    "    db1 = (db1 / L + R_db1) / M;\n",
    "    db2 = (db2 / L + R_db2) / M;\n",
    "    db3 = (db3 / L + R_db3) / M;\n",
    "    db4 = db4 / M;\n",
    "    db5 = db5 / M;\n",
    "\n",
    "    return make_tuple(dW1, dW2, dW3, dW4, dW5, db1, db2, db3, db4, db5, loss);\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For trian_ADAM function, make the following changes\n",
    "\n",
    "// this line is new\n",
    "MatrixXd temp = MatrixXd::Zero(M, dz);\n",
    "\n",
    "// changes to this line is in the end\n",
    "tie(dW1, dW2, dW3, dW4, dW5, db1, db2, db3, db4, db5, loss[i]) = \n",
    "        batch_gradient(X, L, q_W1, q_W2, q_W3, p_W4, p_W5, q_b1, q_b2, q_b3, p_b4, p_b5, temp, temp);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing vs existing functions\n",
    "\n",
    "Note that if we just run these codes without making changes in the section above, then total loss and the gradients will be different because eps and z are different, they are generated in the eigen library. Also here I've temporarily comma out test_total_loss function relevant checkings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_back(q_s2, q_h1, q_W2, q_W3, X):\n",
    "    \"\"\"for testing vs pybind11 + Eigen function\"\"\"\n",
    "    \n",
    "    R_d22 = (q_s2 - 1)/2 # M by dz\n",
    "    dR_dW3 = R_d22.T @ q_h1 # dz by dm\n",
    "    dR_db3 = np.sum(R_d22, axis = 0).reshape(-1,1) # dz by 1\n",
    "    \n",
    "    R_d21 = q_mu # M by dz\n",
    "    dR_dW2 = R_d21.T @ q_h1 # dz by dm\n",
    "    dR_db2 = np.sum(R_d21, axis = 0).reshape(-1,1) # dm by 1\n",
    "\n",
    "    R_d1 = (R_d22 @ q_W3 + R_d21 @ q_W2) * tanh_gradient_nb(q_h1) # M by dm\n",
    "    dR_dW1 = R_d1.T @ X # dm by dx\n",
    "    dR_db1 = np.sum(R_d1, axis = 0).reshape(-1,1) # dm by 1\n",
    "    \n",
    "    return dR_dW1, dR_dW2, dR_dW3, dR_db1, dR_db2, dR_db3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid:  True\n",
      "sigmoid_gradient:  True\n",
      "tanh_gradient:  True\n",
      "tanh:  True\n",
      "encoder_forward:  True\n",
      "decoder_forward:  True\n",
      "encoder_back:  True\n",
      "loss:  False\n",
      "dW:  False\n"
     ]
    }
   ],
   "source": [
    "eigen_lib = cppimport.imp(\"eigen_lib\")\n",
    "\n",
    "# model parameters\n",
    "nBatch = 1 # number of mini-batch to train\n",
    "M = 100 # batch size\n",
    "L = 1 # sample size\n",
    "std_const = 255 # to standardize data\n",
    "dx = 784 # dimension of the input\n",
    "dm = 500 # dimension of the hidden layer\n",
    "dz = 3 # dimension of latent variable\n",
    "alpha = 0.005 # learning rate\n",
    "nP = 1000 # print out status every nP batches\n",
    "\n",
    "# training data\n",
    "trainX = trainX.reshape(trainX.shape[0],-1)\n",
    "\n",
    "X = eigen_lib.get_batch(M, trainX) / std_const;\n",
    "(q_W1, q_W2, q_W3, p_W4, p_W5, q_b1, q_b2, q_b3, p_b4, p_b5) = eigen_lib.init_para(dx, dm, dz, \"xavier\")\n",
    "\n",
    "W = [q_W1, q_W2, q_W3, p_W4, p_W5]\n",
    "b = [q_b1, q_b2, q_b3, p_b4, p_b5]\n",
    "b1 = [q_b1.reshape(-1,1), q_b2.reshape(-1,1), q_b3.reshape(-1,1), p_b4.reshape(-1,1), p_b5.reshape(-1,1)]\n",
    "\n",
    "# encoder forward\n",
    "(eigen_q_h1, eigen_q_a2, eigen_q_mu, eigen_q_s2) = eigen_lib.encoder_forward(X, q_W1, q_W2, q_W3, q_b1, q_b2, q_b3)\n",
    "\n",
    "q_h1, q_a2, q_mu, q_s2 = encoder_forward_vec_nb1(X, W, b1)\n",
    "\n",
    "# decoder forward\n",
    "eps = np.random.randn(M, L, dz)\n",
    "z = sample_z_vec_nb(q_mu, q_s2, eps)\n",
    "\n",
    "eigen_eps = eps.reshape(M, dz)\n",
    "eigen_z = z.reshape(M, dz)\n",
    "\n",
    "eigen_y, eigen_p_h2 = eigen_lib.decoder_forward(p_W4, p_W5, p_b4, p_b5, eigen_z);\n",
    "\n",
    "y, p_h2 = decoder_forward_vec_nb1(W, b1, z)\n",
    "com_y = y.reshape(y.shape[0], y.shape[2])\n",
    "com_p_h2 = p_h2.reshape(p_h2.shape[0], p_h2.shape[2])\n",
    "\n",
    "# decoder back\n",
    "dR_dW1, dR_dW2, dR_dW3, dR_db1, dR_db2, dR_db3 = encoder_back(q_s2, q_h1, q_W2, q_W3, X)\n",
    "\n",
    "d22 = (q_s2 - 1)/2\n",
    "d21 = q_mu\n",
    "eigen_dR_dW1, eigen_dR_dW2, eigen_dR_dW3, eigen_dR_db1, eigen_dR_db2, eigen_dR_db3 = \\\n",
    "eigen_lib.encoder_back(X, q_W2, q_W3, q_s2, q_h1, q_mu, d22, d21)\n",
    "\n",
    "\n",
    "# total loss\n",
    "loss = total_loss_vec_nb(X, y, q_a2, q_mu, q_s2)\n",
    "\n",
    "# eigen_test_loss = eigen_lib.test_total_loss(X, eigen_y, q_a2, q_mu, q_s2, M, L)\n",
    "\n",
    "# batch gradient\n",
    "(eigen_dW1, eigen_dW2, eigen_dW3, eigen_dW4, eigen_dW5, eigen_db1, eigen_db2, eigen_db3, eigen_db4, eigen_db5, \\\n",
    "     eigen_loss) = eigen_lib.batch_gradient(X, L, q_W1, q_W2, q_W3, p_W4, p_W5, q_b1, q_b2, q_b3, p_b4, p_b5)\n",
    "\n",
    "dW1, dW2, dW3, dW4, dW5, db1, db2, db3, db4, db5 =\\\n",
    "    grad_vec2_nb3(X, y, q_W1, q_W2, q_W3, p_W4, p_W5, q_b1.reshape(-1,1), q_b2.reshape(-1,1), \\\n",
    "    q_b3.reshape(-1,1), p_b4.reshape(-1,1), p_b5.reshape(-1,1), q_h1, p_h2, q_mu, q_s2, z, eps)\n",
    "    \n",
    "A = np.array([[1,2,1],\n",
    "              [2,1,0],\n",
    "              [-1,1,2]])\n",
    "\n",
    "B = np.ones((3,3))\n",
    "print(\"sigmoid: \", np.allclose(eigen_lib.sigmoid(A), sigmoid(A)))\n",
    "print(\"sigmoid_gradient: \", np.allclose(eigen_lib.sigmoid_gradient(A), sigmoid_gradient(A)))\n",
    "print(\"tanh_gradient: \", np.allclose(eigen_lib.tanh_gradient(A), tanh_gradient(A)))\n",
    "print(\"tanh: \", np.allclose(eigen_lib.tanh(A), tanh(A)))\n",
    "print(\"encoder_forward: \", np.allclose(eigen_q_h1, q_h1) and np.allclose(eigen_q_a2, q_a2) and \\\n",
    "     np.allclose(eigen_q_mu, q_mu) and np.allclose(eigen_q_s2, q_s2))\n",
    "print(\"decoder_forward: \", np.allclose(eigen_y, com_y) and np.allclose(eigen_p_h2, com_p_h2))\n",
    "print(\"encoder_back: \", np.allclose(eigen_dR_dW1, dR_dW1) and np.allclose(eigen_dR_dW2, dR_dW2) and \\\n",
    "      np.allclose(eigen_dR_dW3, dR_dW3) and np.allclose(eigen_dR_db1.reshape(-1,1), dR_db1) and \\\n",
    "      np.allclose(eigen_dR_db2.reshape(-1,1), dR_db2) and np.allclose(eigen_dR_db3.reshape(-1,1), dR_db3))\n",
    "print(\"loss: \", np.allclose(eigen_loss, loss))\n",
    "print(\"dW: \", np.allclose(eigen_dW1, dW1))\n",
    "# print(eigen_loss, eigen_test_loss, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500 completed.\n",
      "\n",
      "Batch 1000 completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "W, b, loss = train_AEVB_v5(trainX, 1000, nP = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f01f0fe47b8>]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500 completed.\n",
      "Batch 1000 completed.\n"
     ]
    }
   ],
   "source": [
    "W1, b1, loss1 = train_AEVB_v4(trainX, trainy, 1000, nP = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples(trainX, trainy, W, b, Xdim1 = 0, fig1=\"\", fig2=\"\", std_const = 255):\n",
    "    \"\"\"\n",
    "    Randomly sample 36 figures from training data, reconstruct based on \n",
    "    user specified model parameters and plot for comparison.\n",
    "    \n",
    "    Input parameters\n",
    "    ----------\n",
    "    trainX: array_like\n",
    "            Training dataset inputs.\n",
    "            Dimension: number of sample by dx\n",
    "    trainy: array_like\n",
    "            Training dataset labels. \n",
    "            This variable is not currently used in the function. For further developments.\n",
    "    W: list\n",
    "            List of model weights parameters, same format as train_AEVB function output variable W.\n",
    "    b: list\n",
    "            List of model bias parameters, same format as train_AEVB function output variable b.\n",
    "    Xdim1: integer, optional\n",
    "            Dimension1 for X. If not specified, Xdim1 will be set to = Xdim2 = sqrt(dx).\n",
    "    std_const: integer, optional\n",
    "            Normlizing constant to reconstruct data.\n",
    "            Currently default at 255 which is usually used for black and white image data.            \n",
    "    \n",
    "    Output:\n",
    "    ----------\n",
    "    36 random sampled figures from training data and the model-reconstructed ones for comparison\n",
    "    \"\"\"\n",
    "    \n",
    "    dx = trainX.shape[1]\n",
    "    if Xdim1 == 0:\n",
    "        Xdim1 = Xdim2 = int(np.sqrt(dx))\n",
    "    else:\n",
    "        Xdim2 = int(dx / Xdim1)\n",
    "        assert(Xdim2 == int(Xdim2))\n",
    "        \n",
    "    M = 36\n",
    "    n = int(np.sqrt(M))\n",
    "    L = 1\n",
    "    dz, dm = W[1].shape[0], W[1].shape[1]\n",
    "    Spec = [1, M, L, std_const, dx, dm, dz, 0.005, 0]\n",
    "\n",
    "    X = eigen_lib.get_batch(M, trainX) / std_const\n",
    "    eps = np.zeros((M, L, dz))\n",
    "\n",
    "    y, q_h1, p_h2, q_mu, q_s2, z, loss = batch_forward_vec_nb2(Spec, X, W, b, eps)\n",
    "    \n",
    "    fig, ax = plt.subplots(M)\n",
    "    #fig.suptitle('Sample Images')\n",
    "    \n",
    "    for i in range(M):\n",
    "        # define subplot\n",
    "        plt.subplot(n,n,i+1)\n",
    "        plt.axis('off')\n",
    "        # plot raw pixel data\n",
    "        plt.imshow(X[i].reshape(Xdim1, Xdim2) * std_const, cmap=plt.get_cmap('gray'))\n",
    "    # show the figure\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    if fig1 != \"\":\n",
    "        fig.savefig(fig1)\n",
    "\n",
    "    fig, ax = plt.subplots(M)\n",
    "    #fig.suptitle('Reconstructed Images')\n",
    "    \n",
    "    for i in range(M):\n",
    "        # define subplot\n",
    "        plt.subplot(n,n,i+1)\n",
    "        plt.axis('off')\n",
    "        # plot raw pixel data\n",
    "        plt.imshow(y[i,L-1,].reshape(Xdim1, Xdim2) * std_const, cmap=plt.get_cmap('gray'))\n",
    "    # show the figure\n",
    "    plt.show()\n",
    "    if fig2 != \"\":\n",
    "        fig.savefig(fig2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f01eeaf3160>]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that the data format returned by eigen lib for b is different\n",
    "q_b1, q_b2, q_b3, p_b4, p_b5 = b\n",
    "b = [q_b1.reshape(-1,1), q_b2.reshape(-1,1), q_b3.reshape(-1,1), p_b4.reshape(-1,1), p_b5.reshape(-1,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 36 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 36 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_samples(trainX, trainy, W, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 36 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 36 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_samples(trainX, trainy, W1, b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.7.4 Model v5 Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are codes used for profiling. Currently comma out for documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#profile_filename = get_filename(\"profiling_v5\", ext = \".prof\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "*** Profile stats marshalled to file '2020_05_14_22_04_06_Model_v5_profiling_v5.prof'. \n"
     ]
    }
   ],
   "source": [
    "#%prun -q -D $profile_filename train_AEVB_v2(trainX, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p = pstats.Stats(profile_filename)\n",
    "#p.sort_stats('time', 'cumulative').print_stats(5)\n",
    "#pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6 Timing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.6.1 Total training time on 10 mini-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spec = [10, M, 1, std_const, dx, dm, dz, alpha, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.96 s  121 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit train_ADAM(trainX, trainy, Spec, batch_forward, grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.59 s  86.3 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit train_ADAM_nb1(trainX, trainy, Spec, batch_forward_nb1, grad_nb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.94 s  69.5 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit train_ADAM_nb1(trainX, trainy, Spec, batch_forward_vec, grad_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "609 ms  19.1 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit train_ADAM_nb1(trainX, trainy, Spec, batch_forward_vec, grad_vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "730 ms  45.5 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit train_ADAM_nb1(trainX, trainy, Spec, batch_forward_vec_nb1, grad_vec2_nb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.47 s  64.4 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit train_ADAM_nb2(trainX, trainy, 10, M, L, std_const, dx, dm, dz, alpha, batch_forward_nb2, grad_nb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.66 s  115 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit train_ADAM_v2(trainX, trainy, Spec, batch_forward_nb2, grad_nb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%timeit train_ADAM_nb1_pl(trainX, trainy, Spec, batch_forward_vec_nb1, grad_vec2_nb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668 ms  28.1 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit train_ADAM_nb1_pl(trainX, trainy, Spec, batch_forward_vec_nb2, grad_vec2_nb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "631 ms  12.8 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit train_AEVB_v4(trainX, trainy, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.22 s  18.8 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit train_AEVB_v5(trainX, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.6.2 Gradient function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that weirdly, *grad_vec_nb1* can be called and used in training but when timing it will trigger \"cannot unbox heterogenous list\" error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 0.00001\n",
    "nBatch = 10 # number of mini-batch to train\n",
    "M = 100 # batch size\n",
    "L = 1 # sample size\n",
    "std_const = 255 # to standardize data\n",
    "dx = trainX.shape[1] # dimension of the input\n",
    "dm = 500 # dimension of the hidden layer\n",
    "dz = 3 # dimension of latent variable\n",
    "alpha = 0.005 # learning rate\n",
    "nP = 1000 # print out status every nP batches\n",
    "\n",
    "Spec = [nBatch, M, L, std_const, dx, dm, dz, alpha, nP]\n",
    "\n",
    "W,b = init_random(dx, dm, dz)\n",
    "eps = np.random.randn(L, dz)\n",
    "eps1 = np.random.randn(M,L,dz)\n",
    "batchX, batchy = get_Batch(M, trainX, trainy)\n",
    "X = batchX.reshape(M, dx) / std_const\n",
    "\n",
    "y, H, Lt, loss = batch_forward(Spec, X, W, b, eps)\n",
    "q_W1, q_W2, q_W3, p_W4, p_W5 = W\n",
    "q_b1, q_b2, q_b3, p_b4, p_b5 = b\n",
    "q_h1, p_h2 = H\n",
    "q_mu, q_s2, z, eps = Lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421 ms  15.1 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n",
      "286 ms  27.6 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n",
      "449 ms  53.5 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n",
      "13.3 ms  243 s per loop (mean  std. dev. of 7 runs, 100 loops each)\n",
      "13.1 ms  381 s per loop (mean  std. dev. of 7 runs, 100 loops each)\n",
      "301 ms  17.8 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n",
      "14.7 ms  720 s per loop (mean  std. dev. of 7 runs, 100 loops each)\n",
      "75.1 ms  2.01 ms per loop (mean  std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit grad(X, y, W, b, H, Lt)\n",
    "%timeit grad_nb1(X, y, W, b, H, Lt)\n",
    "%timeit grad_vec(X, y, W, b, H, Lt)\n",
    "%timeit grad_vec2(X, y, W, b, H, Lt)\n",
    "%timeit grad_vec2_nb1(X, y, W, b, H, Lt)\n",
    "%timeit grad_nb2(X, y, q_W1, q_W2, q_W3, p_W4, p_W5, q_b1, q_b2, q_b3, p_b4, p_b5, q_h1, p_h2, q_mu, q_s2, z, eps)\n",
    "%timeit grad_vec2_nb3(X, y, q_W1, q_W2, q_W3, p_W4, p_W5, q_b1, q_b2, q_b3, p_b4, p_b5, q_h1, p_h2, q_mu, q_s2, z, eps1)\n",
    "%timeit eigen_lib.batch_gradient(X, L, q_W1, q_W2, q_W3, p_W4, p_W5, q_b1, q_b2, q_b3, p_b4, p_b5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit grad_vec_nb1(X, y, W, b, H, Lt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Checking and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Gradient checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 0.00001\n",
    "nBatch = 1 # number of mini-batch to train\n",
    "M = 100 # batch size\n",
    "L = 2 # sample size\n",
    "std_const = 255 # to standardize data\n",
    "\n",
    "Xdim1, Xdim2 = trainX[0].shape[0], trainX[0].shape[1]\n",
    "dx = Xdim1 * Xdim2 # dimension of the input\n",
    "dm = 500 # dimension of the hidden layer\n",
    "dz = 3 # dimension of latent variable\n",
    "\n",
    "alpha = 0.005 # learning rate\n",
    "\n",
    "nP = 1000 # print out status every nP batches\n",
    "\n",
    "Spec = [nBatch, M, L, std_const, dx, dm, dz, alpha, nP]\n",
    "\n",
    "W,b = init_random(dx, dm, dz)\n",
    "q_W1, q_W2, q_W3, p_W4, p_W5 = W\n",
    "q_b1, q_b2, q_b3, p_b4, p_b5 = b\n",
    "eps = np.random.randn(L, dz)\n",
    "batchX, batchy = get_Batch(M, trainX, trainy)\n",
    "X = batchX.reshape(M, dx) / std_const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, H, Lt, loss1 = batch_forward(Spec, X, W, b, eps)\n",
    "q_h1, p_h2 = H\n",
    "q_mu, q_s2, z, eps = Lt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient checking for \"listed\" versions of the \"grad\" functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dW, db = grad_2(X, y, W, b, H, Lt)\n",
    "dL_dW1, dL_dW2, dL_dW3, dL_dW4, dL_dW5 = dW\n",
    "dL_db1, dL_db2, dL_db3, dL_db4, dL_db5 = db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient checking for \"unlisted\" versions of the \"grad\" functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dW1, dL_dW2, dL_dW3, dL_dW4, dL_dW5, dL_db1, dL_db2, dL_db3, dL_db4, dL_db5 =\\\n",
    "grad_vec2_nb2(X, y, q_W1, q_W2, q_W3, p_W4, p_W5, q_b1, q_b2, q_b3, p_b4, p_b5, q_h1, p_h2, q_mu, q_s2, z, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient checking\n",
    "p_W5_add = p_W5 + delta\n",
    "p_W5_red = p_W5 - delta\n",
    "\n",
    "p_b5_add = p_b5 + delta\n",
    "p_b5_red = p_b5 - delta\n",
    "\n",
    "p_W4_add = p_W4 + delta\n",
    "p_W4_red = p_W4 - delta\n",
    "\n",
    "p_b4_add = p_b4 + delta\n",
    "p_b4_red = p_b4 - delta\n",
    "\n",
    "q_W3_add = q_W3 + delta\n",
    "q_W3_red = q_W3 - delta\n",
    "\n",
    "q_b3_add = q_b3 + delta\n",
    "q_b3_red = q_b3 - delta\n",
    "\n",
    "q_W2_add = q_W2 + delta\n",
    "q_W2_red = q_W2 - delta\n",
    "\n",
    "q_b2_add = q_b2 + delta\n",
    "q_b2_red = q_b2 - delta\n",
    "\n",
    "q_W1_add = q_W1 + delta\n",
    "q_W1_red = q_W1 - delta\n",
    "\n",
    "q_b1_add = q_b1 + delta\n",
    "q_b1_red = q_b1 - delta\n",
    "\n",
    "W5_add = [q_W1, q_W2, q_W3, p_W4, p_W5_add]\n",
    "W5_red = [q_W1, q_W2, q_W3, p_W4, p_W5_red]\n",
    "\n",
    "b5_add = [q_b1, q_b2, q_b3, p_b4, p_b5_add]\n",
    "b5_red = [q_b1, q_b2, q_b3, p_b4, p_b5_red]\n",
    "\n",
    "W4_add = [q_W1, q_W2, q_W3, p_W4_add, p_W5]\n",
    "W4_red = [q_W1, q_W2, q_W3, p_W4_red, p_W5]\n",
    "\n",
    "b4_add = [q_b1, q_b2, q_b3, p_b4_add, p_b5]\n",
    "b4_red = [q_b1, q_b2, q_b3, p_b4_red, p_b5]\n",
    "\n",
    "W3_add = [q_W1, q_W2, q_W3_add, p_W4, p_W5]\n",
    "W3_red = [q_W1, q_W2, q_W3_red, p_W4, p_W5]\n",
    "\n",
    "b3_add = [q_b1, q_b2, q_b3_add, p_b4, p_b5]\n",
    "b3_red = [q_b1, q_b2, q_b3_red, p_b4, p_b5]\n",
    "\n",
    "W2_add = [q_W1, q_W2_add, q_W3, p_W4, p_W5]\n",
    "W2_red = [q_W1, q_W2_red, q_W3, p_W4, p_W5]\n",
    "\n",
    "b2_add = [q_b1, q_b2_add, q_b3, p_b4, p_b5]\n",
    "b2_red = [q_b1, q_b2_red, q_b3, p_b4, p_b5]\n",
    "\n",
    "W1_add = [q_W1_add, q_W2, q_W3, p_W4, p_W5]\n",
    "W1_red = [q_W1_red, q_W2, q_W3, p_W4, p_W5]\n",
    "\n",
    "b1_add = [q_b1_add, q_b2, q_b3, p_b4, p_b5]\n",
    "b1_red = [q_b1_red, q_b2, q_b3, p_b4, p_b5]\n",
    "\n",
    "d,d,d,loss_W5_add = batch_forward(Spec, X, W5_add, b, eps)\n",
    "d,d,d,loss_W5_red = batch_forward(Spec, X, W5_red, b, eps)\n",
    "\n",
    "d,d,d,loss_b5_add = batch_forward(Spec, X, W, b5_add, eps)\n",
    "d,d,d,loss_b5_red = batch_forward(Spec, X, W, b5_red, eps)\n",
    "\n",
    "d,d,d,loss_W4_add = batch_forward(Spec, X, W4_add, b, eps)\n",
    "d,d,d,loss_W4_red = batch_forward(Spec, X, W4_red, b, eps)\n",
    "\n",
    "d,d,d,loss_b4_add = batch_forward(Spec, X, W, b4_add, eps)\n",
    "d,d,d,loss_b4_red = batch_forward(Spec, X, W, b4_red, eps)\n",
    "\n",
    "d,d,d,loss_W3_add = batch_forward(Spec, X, W3_add, b, eps)\n",
    "d,d,d,loss_W3_red = batch_forward(Spec, X, W3_red, b, eps)\n",
    "\n",
    "d,d,d,loss_b3_add = batch_forward(Spec, X, W, b3_add, eps)\n",
    "d,d,d,loss_b3_red = batch_forward(Spec, X, W, b3_red, eps)\n",
    "\n",
    "d,d,d,loss_W2_add = batch_forward(Spec, X, W2_add, b, eps)\n",
    "d,d,d,loss_W2_red = batch_forward(Spec, X, W2_red, b, eps)\n",
    "\n",
    "d,d,d,loss_b2_add = batch_forward(Spec, X, W, b2_add, eps)\n",
    "d,d,d,loss_b2_red = batch_forward(Spec, X, W, b2_red, eps)\n",
    "\n",
    "d,d,d,loss_W1_add = batch_forward(Spec, X, W1_add, b, eps)\n",
    "d,d,d,loss_W1_red = batch_forward(Spec, X, W1_red, b, eps)\n",
    "\n",
    "d,d,d,loss_b1_add = batch_forward(Spec, X, W, b1_add, eps)\n",
    "d,d,d,loss_b1_red = batch_forward(Spec, X, W, b1_red, eps)\n",
    "\n",
    "print(\"var\", \"manual\", \"grad func\")\n",
    "print(\"W5: \", (loss_W5_add - loss_W5_red)/2/delta, np.sum(dL_dW5))\n",
    "print(\"b5: \", (loss_b5_add - loss_b5_red)/2/delta, np.sum(dL_db5))\n",
    "print(\"W4: \", (loss_W4_add - loss_W4_red)/2/delta, np.sum(dL_dW4))\n",
    "print(\"b4: \", (loss_b4_add - loss_b4_red)/2/delta, np.sum(dL_db4))\n",
    "print(\"W3: \", (loss_W3_add - loss_W3_red)/2/delta, np.sum(dL_dW3))\n",
    "print(\"b3: \", (loss_b3_add - loss_b3_red)/2/delta, np.sum(dL_db3))\n",
    "print(\"W2: \", (loss_W2_add - loss_W2_red)/2/delta, np.sum(dL_dW2))\n",
    "print(\"b2: \", (loss_b2_add - loss_b2_red)/2/delta, np.sum(dL_db2))\n",
    "print(\"W1: \", (loss_W1_add - loss_W1_red)/2/delta, np.sum(dL_dW1))\n",
    "print(\"b1: \", (loss_b1_add - loss_b1_red)/2/delta, np.sum(dL_db1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Optimized functions vs original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we test the optimized function vs the original ones to ensure the new functions are correct. Although the implementation involves more than $10$ functions, we can ensure the accuracy by testing the two key functions *grad* and *batch_forward* as they utilize most of the other functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nBatch = 1 # number of mini-batch to train\n",
    "M = 100 # batch size\n",
    "L = 2 # sample size\n",
    "std_const = 255 # to standardize data\n",
    "\n",
    "Xdim1, Xdim2 = trainX[0].shape[0], trainX[0].shape[1]\n",
    "dx = Xdim1 * Xdim2 # dimension of the input\n",
    "dm = 500 # dimension of the hidden layer\n",
    "dz = 3 # dimension of latent variable\n",
    "\n",
    "alpha = 0.005 # learning rate\n",
    "\n",
    "nP = 1000 # print out status every nP batches\n",
    "\n",
    "Spec = [nBatch, M, L, std_const, dx, dm, dz, alpha, nP]\n",
    "\n",
    "W,b = init_random(dx, dm, dz)\n",
    "q_W1, q_W2, q_W3, p_W4, p_W5 = W\n",
    "q_b1, q_b2, q_b3, p_b4, p_b5 = b\n",
    "eps = np.random.randn(L, dz)\n",
    "batchX, batchy = get_Batch(M, trainX, trainy)\n",
    "X = batchX.reshape(M, dx) / std_const"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.1 batch_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_original, H_original, Lt_original, loss_original = batch_forward(Spec, X, W, b, eps)\n",
    "q_h1_original, p_h2_original = H_original\n",
    "q_mu_original, q_s2_original, z_original, eps_original = Lt_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new, q_h1_new, p_h2_new, q_mu_new, q_s2_new, z_new, loss_new = batch_forward_vec_nb2(Spec, X, W, b, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new, q_h1_new, p_h2_new, q_mu_new, q_s2_new, z_new, loss_new = \\\n",
    "batch_forward_nb2(M, L, dm, dz, X, q_W1, q_W2, q_W3, p_W4, p_W5, q_b1, q_b2, q_b3, p_b4, p_b5, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.allclose(y_original, y_new))\n",
    "print(np.allclose(q_h1_original, q_h1_new))\n",
    "print(np.allclose(p_h2_original, p_h2_new))\n",
    "print(np.allclose(q_mu_original, q_mu_new))\n",
    "print(np.allclose(q_s2_original, q_s2_new))\n",
    "print(np.allclose(z_original, z_new))\n",
    "print(np.allclose(loss_original, loss_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, H, Lt, loss = batch_forward(Spec, X, W, b, eps)\n",
    "dW_ori, db_ori = grad(X, y, W, b, H, Lt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nBatch, M, L, std_const, dx, dm, dz, alpha, nP = Spec\n",
    "q_W1, q_W2, q_W3, p_W4, p_W5 = W\n",
    "q_b1, q_b2, q_b3, p_b4, p_b5 = b\n",
    "q_h1, p_h2 = H\n",
    "q_mu, q_s2, z, eps = Lt\n",
    "dJ_dW1, dJ_dW2, dJ_dW3, dJ_dW4, dJ_dW5, dJ_db1, dJ_db2, dJ_db3, dJ_db4, dJ_db5 = \\\n",
    "grad_nb2(X, y, q_W1, q_W2, q_W3, p_W4, p_W5, q_b1, q_b2, q_b3, p_b4, p_b5, q_h1, p_h2, q_mu, q_s2, z, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.allclose(dW_ori[0], dJ_dW1))\n",
    "print(np.allclose(dW_ori[1], dJ_dW2))\n",
    "print(np.allclose(dW_ori[2], dJ_dW3))\n",
    "print(np.allclose(dW_ori[3], dJ_dW4))\n",
    "print(np.allclose(dW_ori[4], dJ_dW5))\n",
    "\n",
    "print(np.allclose(db_ori[0], dJ_db1))\n",
    "print(np.allclose(db_ori[1], dJ_db2))\n",
    "print(np.allclose(db_ori[2], dJ_db3))\n",
    "print(np.allclose(db_ori[3], dJ_db4))\n",
    "print(np.allclose(db_ori[4], dJ_db5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dW_new, db_new = grad_vec_nb1(X, y, W, b, H, Lt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(np.allclose(dW_ori[i], dW_new[i]))\n",
    "    print(np.allclose(db_ori[i], db_new[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Other Testings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.1 sample_z function testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to test the implementation of *sample_z* function in Model v0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test sample_z\n",
    "a = np.array([1,2])\n",
    "b = np.array([4,9])\n",
    "eps = np.array([0.1,0.2])\n",
    "\n",
    "sample_z(a,b,eps) # returns (dz,)\n",
    "\n",
    "tz = np.zeros((M, L, dz))\n",
    "tz[0,0,] = sample_z(a,b,eps)\n",
    "tz[0,0,].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3.2 parameter update function testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During development of the *para_update* function, we encountered weird results and these are testings to find out the reasons behind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check parameter update\n",
    "W1, b1 = para_update(W, b, dW, db, alpha)\n",
    "q_W1_n, q_W2_n, q_W3_n, p_W4_n, p_W5_n = W1\n",
    "q_b1_n, q_b2_n, q_b3_n, p_b4_n, p_b5_n = b1\n",
    "\n",
    "dJ_dW1, dJ_dW2, dJ_dW3, dJ_dW4, dJ_dW5 = dW\n",
    "dJ_db1, dJ_db2, dJ_db3, dJ_db4, dJ_db5 = db\n",
    "\n",
    "print(np.allclose(q_W1_n+alpha*dJ_dW1, q_W1))\n",
    "print(np.allclose(q_b1_n+alpha*dJ_db1, q_b1))\n",
    "print(np.allclose(q_W2_n+alpha*dJ_dW2, q_W2))\n",
    "print(np.allclose(q_b2_n+alpha*dJ_db2, q_b2))\n",
    "print(np.allclose(q_W3_n+alpha*dJ_dW3, q_W3))\n",
    "print(np.allclose(q_b3_n+alpha*dJ_db3, q_b3))\n",
    "print(np.allclose(p_W4_n+alpha*dJ_dW4, p_W4))\n",
    "print(np.allclose(p_b4_n+alpha*dJ_db4, p_b4))\n",
    "print(np.allclose(p_W5_n+alpha*dJ_dW5, p_W5))\n",
    "print(np.allclose(p_b5_n+alpha*dJ_db5, p_b5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for function return list\n",
    "\"\"\"\n",
    "during implementation of ADAM, I first initiated all the s/v/sc/vc variables in one line of codes \n",
    "by assigning them to the same function returns from init_random.\n",
    "Later I realized in this way, they share the same reference that by changing one of them,\n",
    "I'll accidentally change the values of everything else.\n",
    "This test is to prove this.\n",
    "\"\"\"\n",
    "def test_by_ref():\n",
    "    a = [1,2,3]\n",
    "    b = [4,5,6]\n",
    "    return a,b\n",
    "\n",
    "a1,b1 = a2, b2 = test_by_ref()\n",
    "print(\"before any change: \", a1[0], a2[0])\n",
    "a2[0] = a2[0]* 2 + 5\n",
    "print(\"after chancing a2[0] only: \",a1[0], a2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Figures for Final Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import rcParams\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples_final(trainX, trainy, W, b, fig1, fig2, std_const = 255):\n",
    "    \"\"\"\n",
    "    Randomly sample 9 figures from training data, reconstruct based on \n",
    "    user specified model parameters and plot for comparison.\n",
    "    \n",
    "    Input parameters\n",
    "    ----------\n",
    "    trainX: array_like\n",
    "            Training dataset inputs.\n",
    "            Dimension: number of sample by dim1 by dim2\n",
    "    trainy: array_like\n",
    "            Training dataset labels. \n",
    "            This variable is not currently used in the function. For further developments.\n",
    "    W: list\n",
    "            List of model weights parameters, same format as train_AEVB function output variable W.\n",
    "    b: list\n",
    "            List of model bias parameters, same format as train_AEVB function output variable b.\n",
    "    std_const: integer, optional\n",
    "            Normlizing constant to reconstruct data.\n",
    "            Currently default at 255 which is usually used for black and white image data.            \n",
    "    \n",
    "    Output:\n",
    "    ----------\n",
    "    9 random sampled figures from training data and the model-reconstructed ones for comparison\n",
    "    \"\"\"\n",
    "\n",
    "    Xdim1, Xdim2 = trainX[0].shape[0], trainX[0].shape[1]\n",
    "    M = 36\n",
    "    L = 1\n",
    "    dx = Xdim1 * Xdim2\n",
    "    dz, dm = W[1].shape[0], W[1].shape[1]\n",
    "    Spec = [1, M, L, 255, dx, dm, dz, 0.005, 0]\n",
    "    n = int(np.sqrt(M))\n",
    "\n",
    "    batchX, batchy = get_Batch_nb(M, trainX, trainy)\n",
    "    X = batchX.reshape(M, dx) / std_const\n",
    "    eps = np.zeros((L, dz))\n",
    "\n",
    "    y, q_h1, p_h2, q_mu, q_s2, z, loss = batch_forward_vec_nb2(Spec, X, W, b, eps)\n",
    "    \n",
    "    fig, ax = plt.subplots(M)\n",
    "    #fig.suptitle('Sample Images')\n",
    "    \n",
    "    for i in range(M):\n",
    "        # define subplot\n",
    "        plt.subplot(n,n,i+1)\n",
    "        plt.axis('off')\n",
    "        # plot raw pixel data\n",
    "        plt.imshow(batchX[i], cmap=plt.get_cmap('gray'))\n",
    "    # show the figure\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    fig.savefig(fig1)\n",
    "\n",
    "    fig, ax = plt.subplots(M)\n",
    "    #fig.suptitle('Reconstructed Images')\n",
    "    \n",
    "    for i in range(M):\n",
    "        # define subplot\n",
    "        plt.subplot(n,n,i+1)\n",
    "        plt.axis('off')\n",
    "        # plot raw pixel data\n",
    "        plt.imshow(y[i,L-1,].reshape(Xdim1, Xdim2) * std_const, cmap=plt.get_cmap('gray'))\n",
    "    # show the figure\n",
    "\n",
    "    plt.show()\n",
    "    fig.savefig(fig2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_fig(fig1, fig2, output):\n",
    "    \"\"\"helper function for final report\"\"\"\n",
    "    # figure size in inches optional\n",
    "    # rcParams['figure.figsize'] = 11,8\n",
    "\n",
    "    # read images\n",
    "    img_A = mpimg.imread(fig1)\n",
    "    img_B = mpimg.imread(fig2)\n",
    "\n",
    "    # display images\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img_A)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img_B)\n",
    "    plt.show()\n",
    "    fig.set_size_inches(60, 20)\n",
    "    fig.savefig(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Section 2.2.2 baseline model performance reasonabless checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Files/2020_04_22_Model_v1.0.txt\"\n",
    "para = get_para(filename)\n",
    "doc = para['doc']\n",
    "W = para['W']\n",
    "b = para['b']\n",
    "loss = para['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = \"Figs_Raw/Fig1_Sample.png\"\n",
    "fig2 = \"Figs_Raw/Fig1_Reconstructed.png\"\n",
    "plot_samples_final(trainX, trainy, W, b, fig1, fig2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_fig(fig1, fig2, \"Figs/Fig2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "plt.plot(loss)\n",
    "fig.savefig(\"Figs/Fig1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Section 2.3 ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Files/2020_04_24_12_38_14_Model_v1.1_parameter.txt\"\n",
    "para = get_para(filename)\n",
    "doc = para['doc']\n",
    "W = para['W']\n",
    "b = para['b']\n",
    "loss = para['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "plt.plot(loss)\n",
    "fig.savefig(\"Figs/Fig3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Files/2020_04_24_22_18_49_Model_v1.1_parameter.txt\"\n",
    "para = get_para(filename)\n",
    "doc = para['doc']\n",
    "W = para['W']\n",
    "b = para['b']\n",
    "loss = para['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = \"Figs_Raw/Fig4_Sample.png\"\n",
    "fig2 = \"Figs_Raw/Reconstructed.png\"\n",
    "plot_samples_final(trainX, trainy, W, b, fig1, fig2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_fig(fig1, fig2, \"Figs/Fig4.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Section 2.4 Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_filename = \"Files/2020_04_24_11_18_59_Model_v1.1_profiling_v1.prof\"\n",
    "p = pstats.Stats(profile_filename)\n",
    "p.sort_stats('time', 'cumulative').print_stats(5)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4 Section 3.1 MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Files/2020_04_30_Final_Model_dz3_100k_parameter.txt\"\n",
    "para = get_para(filename)\n",
    "doc = para['doc']\n",
    "W = para['W']\n",
    "b = para['b']\n",
    "loss = para['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = \"Figs_Raw/Fig9_Sample.png\"\n",
    "fig2 = \"Figs_Raw/Fig9_Reconstructed.png\"\n",
    "plot_samples_final(trainX, trainy, W, b, fig1, fig2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_fig(fig1, fig2, \"Figs/Fig9.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Files/2020_04_30_Final_Model_dz5_100k_parameter.txt\"\n",
    "para = get_para(filename)\n",
    "doc = para['doc']\n",
    "W = para['W']\n",
    "b = para['b']\n",
    "loss = para['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = \"Figs_Raw/Fig10_Sample.png\"\n",
    "fig2 = \"Figs_Raw/Fig10_Reconstructed.png\"\n",
    "plot_samples_final(trainX, trainy, W, b, fig1, fig2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_fig(fig1, fig2, \"Figs/Fig10.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Files/2020_04_30_Final_Model_dz10_100k_parameter.txt\"\n",
    "para = get_para(filename)\n",
    "doc = para['doc']\n",
    "W = para['W']\n",
    "b = para['b']\n",
    "loss = para['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = \"Figs_Raw/Fig11_Sample.png\"\n",
    "fig2 = \"Figs_Raw/Fig11_Reconstructed.png\"\n",
    "plot_samples_final(trainX, trainy, W, b, fig1, fig2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_fig(fig1, fig2, \"Figs/Fig11.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5 Section 3.2 Caltech Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Files/2020_04_30_22_41_05_Model_v1.3_parameter_Caltech.txt\"\n",
    "para = get_para(filename)\n",
    "doc = para['doc']\n",
    "W = para['W']\n",
    "b = para['b']\n",
    "loss = para['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples_caltech(trainX, trainy, W, b, fig1, fig2, std_const = 255):\n",
    "    \"\"\"\n",
    "    Randomly sample 9 figures from training data, reconstruct based on \n",
    "    user specified model parameters and plot for comparison.\n",
    "    \n",
    "    Input parameters\n",
    "    ----------\n",
    "    trainX: array_like\n",
    "            Training dataset inputs.\n",
    "            Dimension: number of sample by dim1 by dim2 ...\n",
    "    trainy: array_like\n",
    "            Training dataset labels. \n",
    "            This variable is not currently used in the function. For further developments.\n",
    "    W: list\n",
    "            List of model weights parameters, same format as train_AEVB function output variable W.\n",
    "    b: list\n",
    "            List of model bias parameters, same format as train_AEVB function output variable b.\n",
    "    std_const: integer, optional\n",
    "            Normlizing constant to reconstruct data.\n",
    "            Currently default at 255 which is usually used for black and white image data.            \n",
    "    \n",
    "    Output:\n",
    "    ----------\n",
    "    9 random sampled figures from training data and the model-reconstructed ones for comparison\n",
    "    \"\"\"\n",
    "\n",
    "    dx = trainX.shape[1]\n",
    "    M = 36\n",
    "    L = 1\n",
    "    dz, dm = W[1].shape[0], W[1].shape[1]\n",
    "    Xdim1 = Xdim2 = int(np.sqrt(dx))\n",
    "    Spec = [1, M, L, 255, dx, dm, dz, 0.005, 0]\n",
    "    n = int(np.sqrt(M))\n",
    "    \n",
    "    batchX, batchy = get_Batch_nb(M, trainX, trainy)\n",
    "    X = batchX.reshape(M, dx) / std_const\n",
    "    eps = np.zeros((L, dz))\n",
    "    \n",
    "    y, q_h1, p_h2, q_mu, q_s2, z, loss = batch_forward_vec_nb2(Spec, X, W, b, eps)\n",
    "    \n",
    "    fig, ax = plt.subplots(M)\n",
    "    #fig.suptitle('Sample Images')\n",
    "    \n",
    "    for i in range(M):\n",
    "        # define subplot\n",
    "        plt.subplot(n,n,i+1)\n",
    "        plt.axis('off')\n",
    "        # plot raw pixel data\n",
    "        plt.imshow(batchX[i].reshape(Xdim1,Xdim2), cmap=plt.get_cmap('gray'))\n",
    "    # show the figure\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    fig.savefig(fig1)\n",
    "\n",
    "    fig, ax = plt.subplots(M)\n",
    "    #fig.suptitle('Reconstructed Images')\n",
    "    \n",
    "    for i in range(M):\n",
    "        # define subplot\n",
    "        plt.subplot(n,n,i+1)\n",
    "        plt.axis('off')\n",
    "        # plot raw pixel data\n",
    "        plt.imshow(y[i,L-1,].reshape(Xdim1, Xdim2) * std_const, cmap=plt.get_cmap('gray'))\n",
    "    # show the figure\n",
    "\n",
    "    plt.show()\n",
    "    fig.savefig(fig2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "caltech = loadmat('Files/caltech101_silhouettes_16.mat')\n",
    "calX = caltech['X']\n",
    "caly = caltech['Y'].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = \"Figs_Raw/Fig12_Sample.png\"\n",
    "fig2 = \"Figs_Raw/Fig12_Reconstructed.png\"\n",
    "plot_samples_caltech(calX, caly, W, b, fig1, fig2, std_const = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_fig(fig1, fig2, \"Figs/Fig12.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
